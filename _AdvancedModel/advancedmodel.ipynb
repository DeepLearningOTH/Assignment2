{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Djv1JVQ0NlLY"
   },
   "source": [
    "# Sequence Tagging (Named Entity Recognition)\n",
    "# Advanced Example: Bi-Directional LSTM + CRF\n",
    "\n",
    "\n",
    "## Accuracy f1 dev:\n",
    "* Epoch 0: 0.5073 %\n",
    "* Epoch 10: 0.8664 %\n",
    "* Epoch 30: 0.9154 %\n",
    "\n",
    "\n",
    "## Used Tools:\n",
    "\n",
    "* Tensorflow\n",
    "* Keras\n",
    "* GloVe (Word Embedding)\n",
    "\n",
    "## Source:\n",
    "[Sequence Tagging with Tensorflow by Guillaume Genthial](https://guillaumegenthial.github.io/sequence-tagging-with-tensorflow.html)\n",
    "\n",
    "## Full Model:\n",
    "\n",
    "<img src=\"screens/model.png\" alt=\"graph\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IpKBw9k-yvsX"
   },
   "outputs": [],
   "source": [
    "# install keras if necessary\n",
    "# !pip install -q keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFXYv2CfKm-c"
   },
   "source": [
    "## Load packages\n",
    "* numpy\n",
    "* keras\n",
    "* validation.py (helper class)\n",
    "* prepro.py (helper class)\n",
    "* tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "ORnzEnvOsIKg",
    "outputId": "9cad97ca-1da2-4f1e-bbf1-566ab6197f8a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import urllib\n",
    "import urllib.request\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "from validation import compute_f1\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import TimeDistributed, Conv1D, Dense, Embedding, Input, Dropout, LSTM, Bidirectional, MaxPooling1D, \\\n",
    "    Flatten, concatenate\n",
    "from prepro import readfile, createBatches, createMatrices, iterate_minibatches, addCharInformation, padding\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import SGD, Nadam\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3gcM9d9SWV-8"
   },
   "source": [
    "## Parameters:\n",
    "* EPOCHS = 30 (Number of times the training data gets iterated through)\n",
    "* DROPOUT= 0.5 (Probability for a normal neuron to be dropped at one iteration)\n",
    "* DROPOUT_RECURRENT = 0.25 (Probability for a reccurent neuron to be dropped at one iteration)\n",
    "* LSTM_STATE_SIZE = 200 (Size of LSTM)\n",
    "* CONV_SIZE = 3 (Size of convolutional network)\n",
    "* LEARNING RATE = 0.0105 (Learning rate at start, decreases at time)\n",
    "* OPTIMIZER = Nadam() ([Recommended] Nesterov Adam optimizer: Adam optimizer with Nestrov momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7k6zDJEVQS_T"
   },
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "EPOCHS = 30\n",
    "DROPOUT = 0.5 \n",
    "DROPOUT_RECURRENT = 0.25\n",
    "LSTM_STATE_SIZE = 200 \n",
    "CONV_SIZE = 3   \n",
    "LEARNING_RATE = 0.0105\n",
    "OPTIMIZER = Nadam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-jijOgxyfkz5"
   },
   "source": [
    "## Open word embedding GloVe to respresent words as global vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and extract GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Glove 100d txt embedding is in embeddings folder\n",
    "if(not (os.path.isfile(\"../embeddings/glove.6B.100d.txt\"))):\n",
    "    # Check if Glove zip is in embeddings folder\n",
    "    if(not (os.path.isfile(\"../embeddings/glove.6B.zip\"))):\n",
    "        dlurl='http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "        print(\"Downloading GloVe...\")\n",
    "        urllib.request.urlretrieve (dlurl, \"../embeddings/glove.6B.zip\")\n",
    "    \n",
    "    # Extract embedding\n",
    "    with zipfile.ZipFile(\"../embeddings/glove.6B.zip\") as myzip:\n",
    "        print(\"Extracting GloVe...\")\n",
    "        myzip.extract('glove.6B.100d.txt', '../embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PPm75Jg1foIq"
   },
   "outputs": [],
   "source": [
    "fEmbeddings = open(\"../embeddings/glove.6B.100d.txt\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9gH9-0l_g22Z"
   },
   "source": [
    "## Main Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Word level representation from characters embeddings\n",
    "<img src=\"screens/char_representation.png\" alt=\"graph\" width=\"400\"/>\n",
    "\n",
    "### 2. Bidirectional LSTM on top of word representation to extract contextual representation of each word\n",
    "<img src=\"screens/bi-lstm.png\" alt=\"graph\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "O_WwPMo3sIKx",
    "outputId": "83ad9219-66b2-4620-d061-a8c806ab2f2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class initialised.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Initialise class\"\"\"\n",
    "\n",
    "class CNN_BLSTM(object):\n",
    "    \n",
    "    def __init__(self, EPOCHS, DROPOUT, DROPOUT_RECURRENT, LSTM_STATE_SIZE, CONV_SIZE, LEARNING_RATE, OPTIMIZER):\n",
    "        \n",
    "        # Set parameters\n",
    "        self.epochs = EPOCHS\n",
    "        self.dropout = DROPOUT\n",
    "        self.dropout_recurrent = DROPOUT_RECURRENT\n",
    "        self.lstm_state_size = LSTM_STATE_SIZE\n",
    "        self.conv_size = CONV_SIZE\n",
    "        self.learning_rate = LEARNING_RATE\n",
    "        self.optimizer = OPTIMIZER\n",
    "        \n",
    "    def loadData(self):\n",
    "      \n",
    "        # Use the readfile() method of prepro.py to load the data and add character information\n",
    "        self.trainSentences = readfile(\"../data/train.txt\")\n",
    "        self.devSentences = readfile(\"../data/dev.txt\")\n",
    "        self.testSentences = readfile(\"../data/test.txt\")\n",
    "\n",
    "    def addCharInfo(self):\n",
    "      \n",
    "        # Use the addCharInformation() method of prepro.py to format the data to: [['the', ['t', 'h', 'e'], 'O\\n']['EU', ['E', 'U'], 'B-ORG\\n'], ...]\n",
    "        self.trainSentences = addCharInformation(self.trainSentences)\n",
    "        self.devSentences = addCharInformation(self.devSentences)\n",
    "        self.testSentences = addCharInformation(self.testSentences)\n",
    "\n",
    "    def embed(self):\n",
    "        \"\"\"Create word- and character-level embeddings\"\"\"\n",
    "\n",
    "        labelSet = set()\n",
    "        words = {}\n",
    "\n",
    "        # Add unique words and labels of all data files to literals\n",
    "        for dataset in [self.trainSentences, self.devSentences, self.testSentences]:\n",
    "            for sentence in dataset:\n",
    "                for token, char, label in sentence:   \n",
    "                    labelSet.add(label)\n",
    "                    words[token.lower()] = True\n",
    "\n",
    "        # Map labels\n",
    "        self.label2Idx = {}\n",
    "        for label in labelSet:\n",
    "            self.label2Idx[label] = len(self.label2Idx)\n",
    "\n",
    "        # Map token cases\n",
    "        # PADDING_TOKEN: pad sentences to make them the same length\n",
    "        case2Idx = {'numeric': 0, 'allLower': 1, 'allUpper': 2, 'initialUpper': 3, 'other': 4, 'mainly_numeric': 5,\n",
    "                    'contains_digit': 6, 'PADDING_TOKEN': 7}\n",
    "        self.caseEmbeddings = np.identity(len(case2Idx), dtype='float32')  # identity matrix used \n",
    "\n",
    "        # Read GLoVE word embeddings\n",
    "        word2Idx = {}\n",
    "        self.wordEmbeddings = []\n",
    "\n",
    "        \n",
    "\n",
    "        # Loop through words in embeddings\n",
    "        for line in fEmbeddings:\n",
    "            split = line.strip().split(\" \")\n",
    "            word = split[0]  # embedding word entry\n",
    "\n",
    "            if len(word2Idx) == 0:  # add padding+unknown\n",
    "                word2Idx[\"PADDING_TOKEN\"] = len(word2Idx)\n",
    "                vector = np.zeros(len(split) - 1)  # zero vector for 'PADDING' word\n",
    "                self.wordEmbeddings.append(vector)\n",
    "\n",
    "                word2Idx[\"UNKNOWN_TOKEN\"] = len(word2Idx)\n",
    "                vector = np.random.uniform(-0.25, 0.25, len(split) - 1)\n",
    "                self.wordEmbeddings.append(vector)\n",
    "\n",
    "            if split[0].lower() in words:\n",
    "                vector = np.array([float(num) for num in split[1:]])\n",
    "                self.wordEmbeddings.append(vector)  # word embedding vector\n",
    "                word2Idx[split[0]] = len(word2Idx)  # corresponding word dict\n",
    "\n",
    "        self.wordEmbeddings = np.array(self.wordEmbeddings)\n",
    "        \n",
    "        # Create string with possible characters\n",
    "        chars = \" 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ.,-_()[]{}!?:;#'\\\"/\\\\%$`&=*+@^~|<>\"\n",
    "\n",
    "        # Create dictionary of possible characters\n",
    "        self.char2Idx = {\"PADDING\": 0, \"UNKNOWN\": 1}\n",
    "        for c in chars:\n",
    "            self.char2Idx[c] = len(self.char2Idx)\n",
    "\n",
    "        # Use padding() and createMatrices() methods from prepro.py to format the data to: [[wordindices], [caseindices], [padded word indices], [label indices]]\n",
    "        # Create train set\n",
    "        self.train_set = padding(createMatrices(self.trainSentences, word2Idx, self.label2Idx, case2Idx, self.char2Idx))\n",
    "        # Create dev set\n",
    "        self.dev_set = padding(createMatrices(self.devSentences, word2Idx, self.label2Idx, case2Idx, self.char2Idx))\n",
    "        # Create test set\n",
    "        self.test_set = padding(createMatrices(self.testSentences, word2Idx, self.label2Idx, case2Idx, self.char2Idx))\n",
    "\n",
    "        self.idx2Label = {v: k for k, v in self.label2Idx.items()}\n",
    "        \n",
    "    def createBatches(self):\n",
    "        \"\"\"Create batches with createBatches() method in prepro.py\"\"\"\n",
    "        \n",
    "        # Create train batch\n",
    "        self.train_batch, self.train_batch_len = createBatches(self.train_set)\n",
    "        # Create dev batch\n",
    "        self.dev_batch, self.dev_batch_len = createBatches(self.dev_set)\n",
    "        # Create test batch\n",
    "        self.test_batch, self.test_batch_len = createBatches(self.test_set)\n",
    "        \n",
    "    def tag_dataset(self, dataset, model):\n",
    "        \"\"\"Tag data with numerical values\"\"\"\n",
    "        \n",
    "        correctLabels = []\n",
    "        predLabels = []\n",
    "        \n",
    "        for i, data in enumerate(dataset):\n",
    "            tokens, casing, char, labels = data\n",
    "            tokens = np.asarray([tokens])\n",
    "            casing = np.asarray([casing])\n",
    "            char = np.asarray([char])\n",
    "            pred = model.predict([tokens, casing, char], verbose=False)[0]\n",
    "            pred = pred.argmax(axis=-1)  # Predict the classes\n",
    "            correctLabels.append(labels)\n",
    "            predLabels.append(pred)\n",
    "            \n",
    "        return predLabels, correctLabels\n",
    "    \n",
    "    def buildModel(self):\n",
    "        \"\"\"Model layers\"\"\"\n",
    "\n",
    "        # Character input\n",
    "        character_input = Input(shape=(None, 52,), name=\"Character_input\")\n",
    "        embed_char_out = TimeDistributed(\n",
    "            Embedding(len(self.char2Idx), 30, embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name=\"Character_embedding\")(\n",
    "            character_input)\n",
    "\n",
    "        dropout = Dropout(self.dropout)(embed_char_out)\n",
    "\n",
    "        # Convolutional Neural Network\n",
    "        # TimeDistributed(): add additional time dimention\n",
    "        conv1d_out = TimeDistributed(Conv1D(kernel_size=self.conv_size, filters=30, padding='same', activation='tanh', strides=1), name=\"Convolution\")(dropout)\n",
    "        maxpool_out = TimeDistributed(MaxPooling1D(52), name=\"Maxpool\")(conv1d_out)\n",
    "        char = TimeDistributed(Flatten(), name=\"Flatten\")(maxpool_out)\n",
    "        char = Dropout(self.dropout)(char)\n",
    "\n",
    "        # Word-level input\n",
    "        words_input = Input(shape=(None,), dtype='int32', name='words_input')\n",
    "        words = Embedding(input_dim=self.wordEmbeddings.shape[0], output_dim=self.wordEmbeddings.shape[1], weights=[self.wordEmbeddings],\n",
    "                          trainable=False)(words_input)\n",
    "\n",
    "        # Case-info input\n",
    "        casing_input = Input(shape=(None,), dtype='int32', name='casing_input')\n",
    "        casing = Embedding(output_dim=self.caseEmbeddings.shape[1], input_dim=self.caseEmbeddings.shape[0], weights=[self.caseEmbeddings],\n",
    "                           trainable=False)(casing_input)\n",
    "\n",
    "        # Concat & bi-LSTM\n",
    "        output = concatenate([words, casing, char])\n",
    "        output = Bidirectional(LSTM(self.lstm_state_size, \n",
    "                                    return_sequences=True, \n",
    "                                    dropout=self.dropout,                        # on input to each LSTM block\n",
    "                                    recurrent_dropout=self.dropout_recurrent     # on recurrent input signal\n",
    "                                   ), name=\"BLSTM\")(output)\n",
    "        output = TimeDistributed(Dense(len(self.label2Idx), activation='softmax'),name=\"Softmax_layer\")(output)\n",
    "\n",
    "        # Set up model\n",
    "        self.model = Model(inputs=[words_input, casing_input, character_input], outputs=[output])\n",
    "        \n",
    "        self.model.compile(loss='sparse_categorical_crossentropy', optimizer=self.optimizer)\n",
    "        \n",
    "        self.init_weights = self.model.get_weights()\n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"Default training\"\"\"\n",
    "        \n",
    "        # For plotting the learning curve\n",
    "        self.f1_test_history = []\n",
    "        self.f1_dev_history = []\n",
    "\n",
    "        # Run through defined epochs\n",
    "        for epoch in range(self.epochs):    \n",
    "            print(\"Epoch {}/{}\".format(epoch, self.epochs))\n",
    "            for i,batch in enumerate(iterate_minibatches(self.train_batch,self.train_batch_len)):\n",
    "                labels, tokens, casing,char = batch       \n",
    "                self.model.train_on_batch([tokens, casing,char], labels)\n",
    "\n",
    "            # Compute test F1 scores\n",
    "            predLabels, correctLabels = self.tag_dataset(self.test_batch, self.model)\n",
    "            pre_test, rec_test, f1_test = compute_f1(predLabels, correctLabels, self.idx2Label)\n",
    "            self.f1_test_history.append(f1_test)\n",
    "            print(\"   f1 test \", round(f1_test, 4))\n",
    "            \n",
    "            # Compute dev F1 scrores\n",
    "            predLabels, correctLabels = self.tag_dataset(self.dev_batch, self.model)\n",
    "            pre_dev, rec_dev, f1_dev = compute_f1(predLabels, correctLabels, self.idx2Label)\n",
    "            self.f1_dev_history.append(f1_test)\n",
    "            print(\"   f1 dev \", round(f1_dev, 4), \"\\n\")\n",
    "            \n",
    "        print(\"Final F1 test score: \", f1_test)\n",
    "            \n",
    "        print(\"Training finished.\")\n",
    "\n",
    "    print(\"Class initialised.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHTiWtvzRR1e"
   },
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2184
    },
    "colab_type": "code",
    "id": "qfQAqz3QsILF",
    "outputId": "93910efa-8b68-403e-ce7f-0ee8ac7d9824",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/30\n",
      "   f1 test  0.4474\n",
      "   f1 dev  0.4828 \n",
      "\n",
      "Epoch 1/30\n",
      "   f1 test  0.6731\n",
      "   f1 dev  0.7111 \n",
      "\n",
      "Epoch 2/30\n",
      "   f1 test  0.6486\n",
      "   f1 dev  0.689 \n",
      "\n",
      "Epoch 3/30\n",
      "   f1 test  0.7668\n",
      "   f1 dev  0.8061 \n",
      "\n",
      "Epoch 4/30\n",
      "   f1 test  0.7981\n",
      "   f1 dev  0.8208 \n",
      "\n",
      "Epoch 5/30\n",
      "   f1 test  0.7987\n",
      "   f1 dev  0.8232 \n",
      "\n",
      "Epoch 6/30\n",
      "   f1 test  0.8199\n",
      "   f1 dev  0.8353 \n",
      "\n",
      "Epoch 7/30\n",
      "   f1 test  0.8343\n",
      "   f1 dev  0.8506 \n",
      "\n",
      "Epoch 8/30\n",
      "   f1 test  0.8323\n",
      "   f1 dev  0.8474 \n",
      "\n",
      "Epoch 9/30\n",
      "   f1 test  0.8339\n",
      "   f1 dev  0.8604 \n",
      "\n",
      "Epoch 10/30\n",
      "   f1 test  0.8556\n",
      "   f1 dev  0.8713 \n",
      "\n",
      "Epoch 11/30\n",
      "   f1 test  0.8471\n",
      "   f1 dev  0.8683 \n",
      "\n",
      "Epoch 12/30\n",
      "   f1 test  0.8597\n",
      "   f1 dev  0.8859 \n",
      "\n",
      "Epoch 13/30\n",
      "   f1 test  0.8658\n",
      "   f1 dev  0.8825 \n",
      "\n",
      "Epoch 14/30\n",
      "   f1 test  0.8691\n",
      "   f1 dev  0.8945 \n",
      "\n",
      "Epoch 15/30\n",
      "   f1 test  0.8662\n",
      "   f1 dev  0.8879 \n",
      "\n",
      "Epoch 16/30\n",
      "   f1 test  0.8688\n",
      "   f1 dev  0.8954 \n",
      "\n",
      "Epoch 17/30\n",
      "   f1 test  0.8742\n",
      "   f1 dev  0.9012 \n",
      "\n",
      "Epoch 18/30\n",
      "   f1 test  0.8752\n",
      "   f1 dev  0.9049 \n",
      "\n",
      "Epoch 19/30\n",
      "   f1 test  0.8803\n",
      "   f1 dev  0.9087 \n",
      "\n",
      "Epoch 20/30\n",
      "   f1 test  0.88\n",
      "   f1 dev  0.9094 \n",
      "\n",
      "Epoch 21/30\n",
      "   f1 test  0.8744\n",
      "   f1 dev  0.908 \n",
      "\n",
      "Epoch 22/30\n",
      "   f1 test  0.8804\n",
      "   f1 dev  0.9058 \n",
      "\n",
      "Epoch 23/30\n",
      "   f1 test  0.8761\n",
      "   f1 dev  0.9066 \n",
      "\n",
      "Epoch 24/30\n",
      "   f1 test  0.8715\n",
      "   f1 dev  0.9043 \n",
      "\n",
      "Epoch 25/30\n",
      "   f1 test  0.8791\n",
      "   f1 dev  0.9151 \n",
      "\n",
      "Epoch 26/30\n",
      "   f1 test  0.8866\n",
      "   f1 dev  0.9175 \n",
      "\n",
      "Epoch 27/30\n",
      "   f1 test  0.881\n",
      "   f1 dev  0.9179 \n",
      "\n",
      "Epoch 28/30\n",
      "   f1 test  0.8895\n",
      "   f1 dev  0.9209 \n",
      "\n",
      "Epoch 29/30\n",
      "   f1 test  0.8897\n",
      "   f1 dev  0.921 \n",
      "\n",
      "Final F1 test score:  0.8896515311510031\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# Tensorboard setup\n",
    "tensorboard = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "# Create class\n",
    "cnn_blstm = CNN_BLSTM(EPOCHS, DROPOUT, DROPOUT_RECURRENT, LSTM_STATE_SIZE, CONV_SIZE, LEARNING_RATE, OPTIMIZER)\n",
    "# Load data\n",
    "cnn_blstm.loadData()\n",
    "# Add character information\n",
    "cnn_blstm.addCharInfo()\n",
    "# Create word and character embeddings\n",
    "cnn_blstm.embed()\n",
    "# Create batches\n",
    "cnn_blstm.createBatches()\n",
    "# Build network model\n",
    "cnn_blstm.buildModel()\n",
    "# Start training\n",
    "cnn_blstm.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFCTOOpXsILL"
   },
   "source": [
    "# Plot learning curve (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_4XIWM4PsILN"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "8Sz1cMWksILR",
    "outputId": "d6a01304-9f95-4318-e856-c4db226c6664"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnn_blstm.f1_test_history, label = \"F1 test\")\n",
    "plt.plot(cnn_blstm.f1_dev_history, label = \"F1 dev\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"F1 score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZ2FWBF5sILY"
   },
   "source": [
    "# Label distribution (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "-NTY89VUsILa",
    "outputId": "40fb80ee-ab81-475e-fd2c-257a8c600a79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-ORG: 3.1%\n",
      "I-ORG: 1.82%\n",
      "B-MISC: 1.69%\n",
      "I-MISC: 0.57%\n",
      "B-LOC: 3.51%\n",
      "I-LOC: 0.57%\n",
      "B-PER: 3.24%\n",
      "I-PER: 2.22%\n",
      "O: 83.28%\n"
     ]
    }
   ],
   "source": [
    "cnn_blstm = CNN_BLSTM(EPOCHS, DROPOUT, DROPOUT_RECURRENT, LSTM_STATE_SIZE, CONV_SIZE, LEARNING_RATE, OPTIMIZER)\n",
    "cnn_blstm.loadData()\n",
    "\n",
    "category_count = {\"B-ORG\\n\": 0, \"I-ORG\\n\":0, \"B-MISC\\n\": 0, \"I-MISC\\n\":0, \"B-LOC\\n\": 0, \"I-LOC\\n\": 0, \"B-PER\\n\": 0, \"I-PER\\n\": 0, \"O\\n\": 0}\n",
    "total_count = 0\n",
    "\n",
    "for sentence in cnn_blstm.trainSentences:\n",
    "    for word in sentence:\n",
    "        if word[1] in category_count.keys():\n",
    "            category_count[word[1]] += 1\n",
    "            total_count += 1\n",
    "\n",
    "for category, count in category_count.items():\n",
    "    print(\"{}: {}%\".format(category.replace(\"\\n\", \"\"), round((count/total_count)*100, 2)))            "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "nn_CoNLL.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
