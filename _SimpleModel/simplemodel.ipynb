{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5FX2nLGXbDoC"
   },
   "source": [
    "This programm will learn and execute sequence tagging based on LSTM with a following CNN-maxpooling-layer for feature selection.\n",
    "\n",
    "This programm depends on Tensorflow, Keras and Scikit-Learn version 0.20\n",
    "\n",
    "The link to the code is: https://github.com/kamalkraj/Named-Entity-Recognition-with-Bidirectional-LSTM-CNNs\n",
    "\n",
    "\n",
    "But the code was outdated due to scikit-learn >0.16.\n",
    "I updated those problems so it works again.\n",
    "Also the code was split in 3 python files for preprocessing, model and validation which I recombined in this file.\n",
    "\n",
    "Additional a more simple model was added which contains a lstm only. the selection is defined by the cell which will you run. there are more details in the corresponding section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crQp_Mbaa9kW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import zipfile\n",
    "import urllib\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.layers import TimeDistributed,Conv1D,Dense,Embedding,Input,Dropout,LSTM,Bidirectional,MaxPooling1D,Flatten,concatenate\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import Progbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f-UJAabszSA7"
   },
   "outputs": [],
   "source": [
    "# define pathes to download needed data\n",
    "  # datasets\n",
    "path_train = '../data/train.txt'\n",
    "url_train=  'https://raw.githubusercontent.com/Franck-Dernoncourt/NeuroNER/master/data/conll2003/en/train.txt'\n",
    "path_test = '../data/test.txt'\n",
    "url_test = 'https://raw.githubusercontent.com/Franck-Dernoncourt/NeuroNER/master/data/conll2003/en/test.txt'\n",
    "path_valid = '../data/dev.txt'\n",
    "url_valid = 'https://raw.githubusercontent.com/Franck-Dernoncourt/NeuroNER/master/data/conll2003/en/valid.txt'\n",
    "\n",
    "# path to matrix which already contains a mapping from words to vectors. Can be extended locally\n",
    "path_glove = '../embeddings/glove.6B.zip'\n",
    "url_glove = 'http://nlp.stanford.edu/data/glove.6B.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3NpqR8l9a9kc"
   },
   "source": [
    "### Define Methods to preprocess Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jtb1Hslqa9kd"
   },
   "outputs": [],
   "source": [
    "# define how the file with the input-content looks like, build sentences from the file, \n",
    "# per line there will be one sentence. Each word is tagged. The sentences\n",
    "# with later be the train-examples while the tagging will be the learned target\n",
    "\n",
    "def readfile(filename):\n",
    "    '''\n",
    "    read file\n",
    "    return format :\n",
    "    [ ['EU', 'B-ORG'], ['rejects', 'O'], ['German', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['British', 'B-MISC'], ['lamb', 'O'], ['.', 'O'] ]\n",
    "    '''\n",
    "    f = open(filename)\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for line in f:\n",
    "        if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
    "            if len(sentence) > 0:\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "            continue\n",
    "        splits = line.split(' ')\n",
    "        sentence.append([splits[0],splits[-1]])\n",
    "\n",
    "    if len(sentence) >0:\n",
    "        sentences.append(sentence)\n",
    "        sentence = []\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zWqeQTC5a9kh"
   },
   "outputs": [],
   "source": [
    "# define the casing, so we have a word classification. Important words like\n",
    "# names, organization names, countries, towns \n",
    "# are normally written in initialUpperCase or allUpperCase\n",
    "# while for example verbs and adjectives in lowercase.\n",
    "\n",
    "# So the casing helps to get a better result because we have an important\n",
    "# additional classification\n",
    "\n",
    "def getCasing(word, caseLookup):   \n",
    "    casing = 'other'\n",
    "    \n",
    "    numDigits = 0\n",
    "    for char in word:\n",
    "        if char.isdigit():\n",
    "            numDigits += 1\n",
    "            \n",
    "    digitFraction = numDigits / float(len(word))\n",
    "    \n",
    "    if word.isdigit(): #Is a digit\n",
    "        casing = 'numeric'\n",
    "    elif digitFraction > 0.5:\n",
    "        casing = 'mainly_numeric'\n",
    "    elif word.islower(): #All lower case\n",
    "        casing = 'allLower'\n",
    "    elif word.isupper(): #All upper case\n",
    "        casing = 'allUpper'\n",
    "    elif word[0].isupper(): #is a title, initial char upper, then all lower\n",
    "        casing = 'initialUpper'\n",
    "    elif numDigits > 0:\n",
    "        casing = 'contains_digit'\n",
    "    \n",
    "   \n",
    "    return caseLookup[casing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WQBm-a3va9kk"
   },
   "outputs": [],
   "source": [
    "# split the data into small batches, so the processing will be faster\n",
    "# there will be many text examples which could use a lot of memory so \n",
    "# splitting the data in batches is very useful\n",
    "\n",
    "def createBatches(data):\n",
    "    l = []\n",
    "    for i in data:\n",
    "        l.append(len(i[0]))\n",
    "    l = set(l)\n",
    "    batches = []\n",
    "    batch_len = []\n",
    "    z = 0\n",
    "    for i in l:\n",
    "        for batch in data:\n",
    "            if len(batch[0]) == i:\n",
    "                batches.append(batch)\n",
    "                z += 1\n",
    "        batch_len.append(z)\n",
    "    return batches,batch_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSWt_zkua9ko"
   },
   "outputs": [],
   "source": [
    "# here we preprocess the data, so we have the words (as unique numbers which can be processed),\n",
    "# the casing, and the word as a sequence of cased chars (which can be represented \n",
    "# as numbers and so they can be processed, too).\n",
    "# Also all labels will be represented in an array so the words can be classified correctly. \n",
    "\n",
    "# the output will be a matrix which contains the whole dataset of \n",
    "# processable numbers and chars and the label classification.\n",
    "\n",
    "def createMatrices(sentences, word2Idx, label2Idx, case2Idx,char2Idx):\n",
    "    unknownIdx = word2Idx['UNKNOWN_TOKEN']\n",
    "    paddingIdx = word2Idx['PADDING_TOKEN']    \n",
    "        \n",
    "    dataset = []\n",
    "    \n",
    "    wordCount = 0\n",
    "    unknownWordCount = 0\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        wordIndices = []    \n",
    "        caseIndices = []\n",
    "        charIndices = []\n",
    "        labelIndices = []\n",
    "        \n",
    "        for word,char,label in sentence:  \n",
    "            wordCount += 1\n",
    "            if word in word2Idx:\n",
    "                wordIdx = word2Idx[word]\n",
    "            elif word.lower() in word2Idx:\n",
    "                wordIdx = word2Idx[word.lower()]                 \n",
    "            else:\n",
    "                wordIdx = unknownIdx\n",
    "                unknownWordCount += 1\n",
    "            charIdx = []\n",
    "            for x in char:\n",
    "                charIdx.append(char2Idx[x])\n",
    "            #Get the label and map to int            \n",
    "            wordIndices.append(wordIdx)\n",
    "            caseIndices.append(getCasing(word, case2Idx))\n",
    "            charIndices.append(charIdx)\n",
    "            labelIndices.append(label2Idx[label])\n",
    "           \n",
    "        dataset.append([wordIndices, caseIndices, charIndices, labelIndices]) \n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7pbaK_yra9ks"
   },
   "outputs": [],
   "source": [
    "# the iterator will be defined now, so we can later iterate over the dataset\n",
    "# to learn every single data\n",
    "\n",
    "def iterate_minibatches(dataset,batch_len): \n",
    "    start = 0\n",
    "    for i in batch_len:\n",
    "        tokens = []\n",
    "        caseing = []\n",
    "        char = []\n",
    "        labels = []\n",
    "        data = dataset[start:i]\n",
    "        start = i\n",
    "        for dt in data:\n",
    "            t,c,ch,l = dt\n",
    "            l = np.expand_dims(l,-1)\n",
    "            tokens.append(t)\n",
    "            caseing.append(c)\n",
    "            char.append(ch)\n",
    "            labels.append(l)\n",
    "        yield np.asarray(labels),np.asarray(tokens),np.asarray(caseing),np.asarray(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLC_3Eg_a9kv"
   },
   "outputs": [],
   "source": [
    "def addCharInformation(Sentences):\n",
    "    for i,sentence in enumerate(Sentences):\n",
    "        for j,data in enumerate(sentence):\n",
    "            chars = [c for c in data[0]]\n",
    "            Sentences[i][j] = [data[0],chars,data[1]]\n",
    "    return Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70TwonEza9kz"
   },
   "outputs": [],
   "source": [
    "# define a padding so each sentence will have the same length for processing the data\n",
    "\n",
    "def padding(Sentences):\n",
    "    maxlen = 52\n",
    "    for sentence in Sentences:\n",
    "        char = sentence[2]\n",
    "        for x in char:\n",
    "            maxlen = max(maxlen,len(x))\n",
    "    for i,sentence in enumerate(Sentences):\n",
    "        Sentences[i][2] = pad_sequences(Sentences[i][2],52,padding='post')\n",
    "    return Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-yHV8tdta9k4"
   },
   "source": [
    "### Prepare Model and define common variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aR1Rdy9ra9k5"
   },
   "outputs": [],
   "source": [
    "# Define common variables\n",
    "\n",
    "epochs = 80\n",
    "num_train_f1score_details = 16 # this is how often the f1score will be calculated and displayed while training (example: 50 epochs and this value = 10 will result in displaying the scores in epoch 5, 10, 15, 20, 25, 30, 35, 40, 45, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fLUfZ-YKa9k-"
   },
   "outputs": [],
   "source": [
    "# define how to learn the tagging of the dataset\n",
    "\n",
    "def tag_dataset(dataset):\n",
    "    correctLabels = []\n",
    "    predLabels = []\n",
    "    b = Progbar(len(dataset))\n",
    "    for i,data in enumerate(dataset):    \n",
    "        tokens, casing,char, labels = data\n",
    "        tokens = np.asarray([tokens])     \n",
    "        casing = np.asarray([casing])\n",
    "        char = np.asarray([char])\n",
    "        pred = model.predict([tokens, casing,char], verbose=False)[0]   \n",
    "        pred = pred.argmax(axis=-1) #Predict the classes of labels           \n",
    "        correctLabels.append(labels)\n",
    "        predLabels.append(pred)\n",
    "        b.update(i)\n",
    "    return predLabels, correctLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W3BB7pzZa9lA"
   },
   "outputs": [],
   "source": [
    "# define how to get the train, test and validation data\n",
    "\n",
    "path_to_train_file = tf.keras.utils.get_file('train.txt', path_train)\n",
    "path_to_test_file = tf.keras.utils.get_file('test.txt', path_test)\n",
    "path_to_validation_file = tf.keras.utils.get_file('valid.txt', path_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CdkyOuZaa9lE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Simon\\\\.keras\\\\datasets\\\\train.txt'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check where the file is available\n",
    "\n",
    "path_to_train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNs_O6_aa9lI"
   },
   "outputs": [],
   "source": [
    "# read the files to get the raw content\n",
    "\n",
    "trainSentences = readfile(path_to_train_file)\n",
    "devSentences = readfile(path_to_validation_file)\n",
    "testSentences = readfile(path_to_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZG_-ufba9lM"
   },
   "outputs": [],
   "source": [
    "trainSentences = addCharInformation(trainSentences)\n",
    "devSentences = addCharInformation(devSentences)\n",
    "testSentences = addCharInformation(testSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYr5N6cga9lO"
   },
   "outputs": [],
   "source": [
    "# prepare the labelSet and the sentences\n",
    "\n",
    "labelSet = set()\n",
    "words = {}\n",
    "\n",
    "for dataset in [trainSentences, devSentences, testSentences]:\n",
    "    for sentence in dataset:\n",
    "        for token,char,label in sentence:\n",
    "            labelSet.add(label)\n",
    "            words[token.lower()] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u1sB22hoa9lS"
   },
   "outputs": [],
   "source": [
    "# :: Create a mapping for the labels ::\n",
    "label2Idx = {}\n",
    "for label in labelSet:\n",
    "    label2Idx[label] = len(label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYdKTiN5a9lW"
   },
   "outputs": [],
   "source": [
    "# :: Hard coded case lookup ::\n",
    "case2Idx = {'numeric': 0, 'allLower':1, 'allUpper':2, 'initialUpper':3, 'other':4, 'mainly_numeric':5, 'contains_digit': 6, 'PADDING_TOKEN':7}\n",
    "caseEmbeddings = np.identity(len(case2Idx), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgLOb7DOa9la"
   },
   "outputs": [],
   "source": [
    "# :: Read in word embeddings ::\n",
    "word2Idx = {}\n",
    "wordEmbeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Glove 100d txt embedding is in embeddings folder\n",
    "if(not (os.path.isfile(\"../embeddings/glove.6B.100d.txt\"))):\n",
    "    # Check if Glove zip is in embeddings folder\n",
    "    if(not (os.path.isfile(\"../embeddings/glove.6B.zip\"))):\n",
    "        dlurl='http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "        print(\"Downloading GloVe...\")\n",
    "        urllib.request.urlretrieve (dlurl, \"../embeddings/glove.6B.zip\")\n",
    "    \n",
    "    # Extract embedding\n",
    "    with zipfile.ZipFile(\"../embeddings/glove.6B.zip\") as myzip:\n",
    "        print(\"Extracting GloVe...\")\n",
    "        myzip.extract('glove.6B.100d.txt', '../embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9LUBVhMa9lm"
   },
   "outputs": [],
   "source": [
    "# read the file which contains the prepared matrix, the file with 100d is chosen, \n",
    "# there are also files with 50d and 300d available in the zip \n",
    "# the only difference is the performance of the learner and this programm to read all vectors\n",
    "zip = zipfile.ZipFile('../embeddings/glove.6B.zip')\n",
    "fEmbeddings = zip.open('glove.6B.100d.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5kUXha4Ea9lp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zipfile.ZipExtFile name='glove.6B.100d.txt' mode='r' compress_type=deflate>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the file-reading is ok\n",
    "fEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xt0jTsjSa9lw"
   },
   "outputs": [],
   "source": [
    "# adapt the vector with the prepared matrix (mapping word->vector) to\n",
    "# our examples to have a more words to choose and classify which can \n",
    "# influence our model in both ways (making it better because we know more words\n",
    "# which can help with new sentences for example in the tests,\n",
    "# or making it worse because we have more words as we need)\n",
    "\n",
    "for line in fEmbeddings:\n",
    "    split = line.strip().split(b' ')\n",
    "    word = split[0]\n",
    "    \n",
    "    if len(word2Idx) == 0: #Add padding+unknown\n",
    "        word2Idx[\"PADDING_TOKEN\"] = len(word2Idx)\n",
    "        vector = np.zeros(len(split)-1) #Zero vector vor 'PADDING' word\n",
    "        wordEmbeddings.append(vector)\n",
    "        \n",
    "        word2Idx[\"UNKNOWN_TOKEN\"] = len(word2Idx)\n",
    "        vector = np.random.uniform(-0.25, 0.25, len(split)-1)\n",
    "        wordEmbeddings.append(vector)\n",
    "\n",
    "    if split[0].lower() in words:\n",
    "        vector = np.array([float(num) for num in split[1:]])\n",
    "        wordEmbeddings.append(vector)\n",
    "        word2Idx[split[0]] = len(word2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WP34N08Ia9lz"
   },
   "outputs": [],
   "source": [
    "#classify known vs. unknown token\n",
    "\n",
    "wordEmbeddings = np.array(wordEmbeddings)\n",
    "char2Idx = {\"PADDING_TOKEN\":0, \"UNKNOWN_TOKEN\":1}\n",
    "for c in \" 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ.,-_()[]{}!?:;#'\\\"/\\\\%$`&=*+@^~|\":\n",
    "    char2Idx[c] = len(char2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IPM2tUQra9l1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PADDING_TOKEN': 0, 'UNKNOWN_TOKEN': 1}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2Idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PjZ95eEBn-Sg"
   },
   "source": [
    "Real data preprocessing - from the dataset(sentences and labels)  to the processable matrices with paddings, and preparing the batches - starts now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bf2awUcRa9l5"
   },
   "outputs": [],
   "source": [
    "# create the padding around our sentences in the datasets now\n",
    "\n",
    "train_set = padding(createMatrices(trainSentences,word2Idx,label2Idx,case2Idx,char2Idx))\n",
    "dev_set = padding(createMatrices(devSentences,word2Idx,label2Idx,case2Idx,char2Idx))\n",
    "test_set = padding(createMatrices(testSentences,word2Idx,label2Idx,case2Idx,char2Idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPrKsmQ7a9l9"
   },
   "outputs": [],
   "source": [
    "# create mapping position to label\n",
    "\n",
    "idx2Label = {v: k for k, v in label2Idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vb6jmINya9mA"
   },
   "outputs": [],
   "source": [
    "# create the batches\n",
    "\n",
    "train_batch,train_batch_len = createBatches(train_set)\n",
    "dev_batch,dev_batch_len = createBatches(dev_set)\n",
    "test_batch,test_batch_len = createBatches(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLY RUN ONE OF THE FOLLOWING TWO MODEL-ARCHITECTURES\n",
    "## The first one is more complex with a bidirectional lstm and a cnn layer with maxpooling \n",
    "## The second one is a simple lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0k4Z5dqva9mF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 30) 2850        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, None, 52, 30) 0           char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, None, 52, 30) 2730        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, None, 1, 30)  0           time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, None, 30)     0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, None, 100)    200         words_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, None, 30)     0           time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, 138)    0           embedding_7[0][0]                \n",
      "                                                                 embedding_8[0][0]                \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 400)    542400      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, None, 9)      3609        bidirectional_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 551,853\n",
      "Trainable params: 551,589\n",
      "Non-trainable params: 264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "words_input = Input(shape=(None,),dtype='int32',name='words_input')\n",
    "words = Embedding(input_dim=wordEmbeddings.shape[0], output_dim=wordEmbeddings.shape[1],  weights=[wordEmbeddings], trainable=False)(words_input)\n",
    "casing_input = Input(shape=(None,), dtype='int32', name='casing_input')\n",
    "casing = Embedding(output_dim=caseEmbeddings.shape[1], input_dim=caseEmbeddings.shape[0], weights=[caseEmbeddings], trainable=False)(casing_input)\n",
    "character_input=Input(shape=(None,52,),name='char_input')\n",
    "embed_char_out=TimeDistributed(Embedding(len(char2Idx),30,embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(character_input)\n",
    "dropout= Dropout(0.5)(embed_char_out)\n",
    "conv1d_out= TimeDistributed(Conv1D(kernel_size=3, filters=30, padding='same',activation='tanh', strides=1))(dropout)\n",
    "maxpool_out=TimeDistributed(MaxPooling1D(52))(conv1d_out)\n",
    "char = TimeDistributed(Flatten())(maxpool_out)\n",
    "char = Dropout(0.5)(char)\n",
    "output = concatenate([words, casing,char])\n",
    "output = Bidirectional(LSTM(200, return_sequences=True, dropout=0.50, recurrent_dropout=0.25))(output)\n",
    "output = TimeDistributed(Dense(len(label2Idx), activation='softmax'))(output)\n",
    "model = Model(inputs=[words_input, casing_input,character_input], outputs=[output])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 30) 2850        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, None, 1560)   0           char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, None, 100)    200         words_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, None, 1560)   0           time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, 1668)   0           embedding_10[0][0]               \n",
      "                                                                 embedding_11[0][0]               \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, None, 200)    1495200     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, None, 9)      1809        lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,500,123\n",
      "Trainable params: 1,499,859\n",
      "Non-trainable params: 264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "words_input = Input(shape=(None,),dtype='int32',name='words_input')\n",
    "words = Embedding(input_dim=wordEmbeddings.shape[0], output_dim=wordEmbeddings.shape[1],  weights=[wordEmbeddings], trainable=False)(words_input)\n",
    "casing_input = Input(shape=(None,), dtype='int32', name='casing_input')\n",
    "casing = Embedding(output_dim=caseEmbeddings.shape[1], input_dim=caseEmbeddings.shape[0], weights=[caseEmbeddings], trainable=False)(casing_input)\n",
    "character_input=Input(shape=(None,52,),name='char_input')\n",
    "embed_char_out=TimeDistributed(Embedding(len(char2Idx),30,embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(character_input)\n",
    "char = TimeDistributed(Flatten())(embed_char_out)\n",
    "char = Dropout(0.5)(char)\n",
    "output = concatenate([words, casing,char])\n",
    "output = LSTM(200, return_sequences=True, dropout=0.50, recurrent_dropout=0.25)(output)\n",
    "output = TimeDistributed(Dense(len(label2Idx), activation='softmax'))(output)\n",
    "model = Model(inputs=[words_input, casing_input,character_input], outputs=[output])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cXYHZWDypCjS"
   },
   "source": [
    "## Define Methods for getting any validation score, here the accuracy will be defined by the f1score via the precision and the recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KmY48HRda9mR"
   },
   "outputs": [],
   "source": [
    "def compute_precision(guessed_sentences, correct_sentences):\n",
    "    assert(len(guessed_sentences) == len(correct_sentences))\n",
    "    correctCount = 0\n",
    "    count = 0\n",
    "    \n",
    "    \n",
    "    for sentenceIdx in range(len(guessed_sentences)):\n",
    "        guessed = guessed_sentences[sentenceIdx]\n",
    "        correct = correct_sentences[sentenceIdx]\n",
    "        assert(len(guessed) == len(correct))\n",
    "        idx = 0\n",
    "        while idx < len(guessed):\n",
    "            if guessed[idx][0] == 'B': #A new chunk starts\n",
    "                count += 1\n",
    "                \n",
    "                if guessed[idx] == correct[idx]:\n",
    "                    idx += 1\n",
    "                    correctlyFound = True\n",
    "                    \n",
    "                    while idx < len(guessed) and guessed[idx][0] == 'I': #Scan until it no longer starts with I\n",
    "                        if guessed[idx] != correct[idx]:\n",
    "                            correctlyFound = False\n",
    "                        \n",
    "                        idx += 1\n",
    "                    \n",
    "                    if idx < len(guessed):\n",
    "                        if correct[idx][0] == 'I': #The chunk in correct was longer\n",
    "                            correctlyFound = False\n",
    "                        \n",
    "                    \n",
    "                    if correctlyFound:\n",
    "                        correctCount += 1\n",
    "                else:\n",
    "                    idx += 1\n",
    "            else:  \n",
    "                idx += 1\n",
    "    \n",
    "    precision = 0\n",
    "    if count > 0:    \n",
    "        precision = float(correctCount) / count\n",
    "        \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZYJk7VLa9mO"
   },
   "outputs": [],
   "source": [
    "#Method to compute the accuracy. Call predict_labels to get the labels for the dataset\n",
    "def compute_f1(predictions, correct, idx2Label): \n",
    "    label_pred = []    \n",
    "    for sentence in predictions:\n",
    "        label_pred.append([idx2Label[element] for element in sentence])\n",
    "        \n",
    "    label_correct = []    \n",
    "    for sentence in correct:\n",
    "        label_correct.append([idx2Label[element] for element in sentence])\n",
    "            \n",
    "    \n",
    "    #print label_pred\n",
    "    #print label_correct\n",
    "    \n",
    "    prec = compute_precision(label_pred, label_correct)\n",
    "    rec = compute_precision(label_correct, label_pred)\n",
    "    \n",
    "    f1 = 0\n",
    "    if (rec+prec) > 0:\n",
    "        f1 = 2.0 * prec * rec / (prec + rec);\n",
    "        \n",
    "    return prec, rec, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B7_l1fcpo_SW"
   },
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define array to save f1_scores during training to get an impression of the training quality\n",
    "\n",
    "score_per_time = np.zeros(num_train_f1score_details) # in the epochs defined by num_train_f1score_details (see calculation above) the f1_score can be saved here\n",
    "score_per_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuryIaGna9mJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 1/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 2/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 3/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 4/80\n",
      "14039/14041 [============================>.] - ETA: 0sPrec: 26.894%, Rec: 27.546%, F1: 27.216%\n",
      " \n",
      "Epoch 5/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 6/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 7/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 8/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 9/80\n",
      "14038/14041 [============================>.] - ETA: 0sPrec: 42.412%, Rec: 40.019%, F1: 41.181%\n",
      " \n",
      "Epoch 10/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 11/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 12/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 13/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 14/80\n",
      "14040/14041 [============================>.] - ETA: 0sPrec: 56.201%, Rec: 51.564%, F1: 53.783%\n",
      " \n",
      "Epoch 15/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 16/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 17/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 18/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 19/80\n",
      "14038/14041 [============================>.] - ETA: 0sPrec: 61.644%, Rec: 57.177%, F1: 59.327%\n",
      " \n",
      "Epoch 20/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 21/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 22/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 23/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 24/80\n",
      "14040/14041 [============================>.] - ETA: 0sPrec: 66.349%, Rec: 58.683%, F1: 62.281%\n",
      " \n",
      "Epoch 25/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 26/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 27/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 28/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 29/80\n",
      "14040/14041 [============================>.] - ETA: 0sPrec: 67.973%, Rec: 63.394%, F1: 65.604%\n",
      " \n",
      "Epoch 30/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 31/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 32/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 33/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 34/80\n",
      "14039/14041 [============================>.] - ETA: 0sPrec: 69.340%, Rec: 65.530%, F1: 67.381%\n",
      " \n",
      "Epoch 35/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 36/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 37/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 38/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 39/80\n",
      "14040/14041 [============================>.] - ETA: 0sPrec: 71.662%, Rec: 67.271%, F1: 69.397%\n",
      " \n",
      "Epoch 40/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 41/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 42/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 43/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 44/80\n",
      "14040/14041 [============================>.] - ETA: 0sPrec: 73.798%, Rec: 70.177%, F1: 71.942%\n",
      " \n",
      "Epoch 45/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 46/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 47/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 48/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 49/80\n",
      "14039/14041 [============================>.] - ETA: 0sPrec: 74.978%, Rec: 71.816%, F1: 73.363%\n",
      " \n",
      "Epoch 50/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 51/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 52/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 53/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 54/80\n",
      "14040/14041 [============================>.] - ETA: 0sPrec: 76.826%, Rec: 72.092%, F1: 74.384%\n",
      " \n",
      "Epoch 55/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 56/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 57/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 58/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 59/80\n",
      "14037/14041 [============================>.] - ETA: 0sPrec: 77.312%, Rec: 74.522%, F1: 75.892%\n",
      " \n",
      "Epoch 60/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 61/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 62/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 63/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 64/80\n",
      "14036/14041 [============================>.] - ETA: 0sPrec: 79.389%, Rec: 75.812%, F1: 77.559%\n",
      " \n",
      "Epoch 65/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 66/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 67/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 68/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 69/80\n",
      "14037/14041 [============================>.] - ETA: 0sPrec: 79.758%, Rec: 76.042%, F1: 77.855%\n",
      " \n",
      "Epoch 70/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 71/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 72/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 73/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 74/80\n",
      "14037/14041 [============================>.] - ETA: 0sPrec: 79.802%, Rec: 76.552%, F1: 78.143%\n",
      " \n",
      "Epoch 75/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 76/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 77/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 78/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 79/80\n",
      "14039/14041 [============================>.] - ETA: 0sPrec: 80.140%, Rec: 77.208%, F1: 78.647%\n",
      " \n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for epoch in range(epochs):    \n",
    "    print(\"Epoch %d/%d\"%(epoch,epochs))\n",
    "    a = Progbar(len(train_batch_len))\n",
    "    for i,batch in enumerate(iterate_minibatches(train_batch,train_batch_len)):\n",
    "        labels, tokens, casing,char = batch       \n",
    "        model.train_on_batch([tokens, casing,char], labels)\n",
    "               \n",
    "        a.update(i)\n",
    "    if epoch % (epochs/num_train_f1score_details) == (epochs/num_train_f1score_details)-1:\n",
    "        predLabels, correctLabels = tag_dataset(train_batch)  \n",
    "        precision_train, recall_train, f1_train= compute_f1(predLabels, correctLabels, idx2Label)\n",
    "        score_per_time[index] = f1_train\n",
    "        index = index + 1\n",
    "        print(\"Prec: %.3f%%, Rec: %.3f%%, F1: %.3f%%\" % (precision_train*100, recall_train*100, f1_train*100))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEKCAYAAADw2zkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VfWd//HXJwsJgZAASSCQICDIJsgSFUWt+1ZbbAvW1rrVZabtjLadRbv/pu1vamfaX5fpMnWqHVyr4EKrVuqC1gXBBJAdWQwkJGRhyQZk/fz+uAeNCOQCuTk3yfv5eNzHvefcc5M3JLnve75nM3dHRER6t4SwA4iISPhUBiIiojIQERGVgYiIoDIQERFUBiIigspARERQGYiICCoDEREBksIOEK2srCwfOXJk2DFERLqVoqKianfP7mi5mJeBmX0NuBVwYDVwM5AL/BEYBCwHrnf3pqN9nZEjR1JYWBjjtCIiPYuZbYtmuZgOE5nZcOAOoMDdTwUSgWuBHwM/c/exwB7glljmEBGRo+uKbQZJQF8zSwLSgHLgQmBB8Pw84OouyCEiIkcQ0zJw9x3AT4DtREqgBigC9rp7S7BYKTA8ljlEROToYj1MNBCYDYwChgH9gCsOs+hhz6NtZrebWaGZFVZVVcUuqIhILxfrYaKLgffcvcrdm4EngbOBzGDYCCAPKDvci939XncvcPeC7OwON4aLiMhxinUZbAdmmlmamRlwEbAOWAzMCZa5EVgY4xwiInIUsd5msJTIhuLlRHYrTQDuBe4Cvm5mm4HBwH2xzCEiIkcX8+MM3P17wPcOmb0VOCPW31tEpLtwd+obW6iqa6SyrpGqg7f6Rv750nEkJlhMv3+3OQJZRKQ7amltY1dDU/Amf+D9N/nKQ+6r6hrZ39z6kdcnJxq3nTuaQf36xDSnykBEpANtbU5DUwv1jS3UH2ihLrj/6HQzuxuaqapvpLL2ANX1jexqaMIPs79kRt9kstNTyElPYdqITHLSU8gObjnpqe8/l9E3mcgm19hSGYhIj9Xa5sGbdTP1jS3UHfjgzbvuQPP7b+h17d7Y6xsPvrk3vz+voemjn9gPp29yIplpyeSkp5A3sC/TRgx8/029/X1W/xRSkxNj/K8/NioDEekWdtU3suy93dTsb6au3afxugMfvNEffBM/+Oa+L4o3cTPon5JEekoS/VOT6J+SREbfZPIy+9K/3bz04P7g9IeeS0mmX0oiSYnd90TQKgMRiVslu/exaO1O/rqugsLi3bQdMtzS/k05PTWJAalJDM9MJT0l+f15B9/I01OT3192QGoS/YNl0pITSYjxxtnuQGUgInHD3dlYUceiNRUsWruTdeW1AIwbks4/XDCGC8bnMGRAKv1Tk+jXJynme9j0JioDEQlVW5uzomQPi9ZGCmDbrn2YwfQRA/nmleO5dOJQRmb1Cztmj6cyEJEu19TSxptbqlm0toIX1lVQXd9IcqJx1slZ3H7eaC6ZOISc9NSwY/YqKgMR6RINjS28srGKRWt3snhDJXWNLaT1SeSCcTlcOmkIF4zPYUBqctgxey2VgYjEzK76Rl5cX8GitRW8vrmappY2BvXrwxWTh3LZpKHMGpMVd7tY9lYqAxHpNG1tzrryWl7ZWMkrG6tYvn0PbQ7DM/ty3ZkjuGzSUApOGtitd8HsqVQGInJCavY187dNVbyysYpX362iur4RgMnDM/iHC8Zw6aShTBo2oEuOopXjpzIQkWPS1uasLQs+/b9bxYrg039G32TOOyWb80/J5rxTsslOTwk7qhwDlYGIdGjvviZe21TN4o2V/O3d6g99+v/KBWM4f1w2p+VlavinG1MZiMhHHOnTf2ZaMueO1af/nkhlICIA7G5o4vXN1bxyyKf/KXmRsf+Pjcthan6mjvrtoVQGIr2Mu1NR28iaHTWsLatlTVkN68pq2bF3PxD59H/e2GzOHxf59J/VX5/+ewOVgUgP5u5s372PNTtqWVtWw5qyWtbuqGFXQxMQOWPnqKx+TD9pIDecdRIFIwfp038vpTIQ6SFaWtvYUtUQedMP3vzXldVS19gCQFKCMXZIOheOz2HSsAGcOjyDCbkD6JeitwFRGYh0S61tzvryWlbvqHl/uGd9eS2NLW0ApCYnMH7oAGZPG8akYRmcOiyDU4b2JyVJR/vK4akMRLqJbbsaeG1TNW9srubNLbuo2d8MQHpKEhOHDeALM0/i1OEDmDQsg9FZ/bSbpxwTlYFInNq7r4k3t+zitU3VvL65ipLdkQ28uRmpXDpxCOeMzWJqfib5A9N0cRY5YSoDkTjR2NJK0bY9vLG5mtc3VbNqRw3ukat5zRw9iFtmjeKcsdmcnN1Pp3aQTqcyEAnJwat6vb6pmtc2VbPsvd3sb24lMcGYmp/JHReO5dyxWZyWn0myhnwkxlQGIl2oovYAr2+q5vXNkVtVXeTArtHZ/ZhbkMc5Y7KYefJgnddfupzKQCTGGhpbeGTpdh4vLGFTZT0Ag/r1YdaYLM4dk8WssVkMz+wbckrp7VQGIjFSs7+ZeW8Wc/8b77F3XzOnjxzI3VeM55wxWUzMHaCNvhJXVAYinWxXfSP3vf4eDy7ZRl1jCxeNz+ErF45h+oiBYUcTOSKVgUgn2VlzgHv/tpVHlm2jsaWNK0/N5csXnMykYRlhRxPpkMpA5ASV7N7Hb1/dwoLCUlrdmT11GF8+fwxjcvqHHU0kajEtAzMbBzzWbtZo4LvAA8H8kUAxcI2774llFpHOtrmynt+8spmFK8tINGNOQR5f+tjJ5A9KCzuayDGLaRm4+0ZgKoCZJQI7gKeAu4GX3P0eM7s7mL4rlllEOsvashp+s3gLz60pJyUpgZvOHslt545maEZq2NFEjltXDhNdBGxx921mNhs4P5g/D3gFlYHEuaJte/j14s28vKGS9JQkvnz+yXxx1igG63z/0gN0ZRlcCzwaPB7i7uUA7l5uZjmHe4GZ3Q7cDjBixIguCSnSnruzZOsufvXyZt7csovMtGT+6ZJTuOHskWT01YFh0nOYu8f+m5j1AcqASe5eYWZ73T2z3fN73P2o+90VFBR4YWFhrKOKAJESWLyxkl+9vJnl2/eSnZ7C7eeO5vNnjtD5/6VbMbMidy/oaLmu+q2+Alju7hXBdIWZ5QZrBblAZRflEDmq6vpGnl6xg8cLS3i3op7hmX35wexJzC3IJzVZ1wKQnquryuBzfDBEBPAn4EbgnuB+YRflEPmIltY2XtlYxfyiEl5aX0lLmzM1P5P/nDOFq6cN10nipFeIeRmYWRpwCfB37WbfAzxuZrcA24G5sc4hcqjNlfXMLyrhyeU7qKprJKt/H754zijmzshj7JD0sOOJdKmYl4G77wMGHzJvF5G9i0S6VN2BZp5dVc7jhSUs376XxATjgnE5XFOQxwXjc7QWIL2WtoRJj+fuLHtvN48XlvLc6nL2N7cyJqc/37xyPFdPG05Ouo4PEFEZSI9VXrOfJ4pKmV9UyrZd++ifksTV04ZzTUEeU/MzdbUwkXZUBtKjNLa08sK6Ch4vLOW1TVW4w1mjB/PVi8dy+aRc+vbRHkEih6MykG7P3VlbVsuColKeXrmDvfuaGZaRyj9eMIY5M/IZMVjnChLpiMpAuqWD1w9+dlU5z64qZ2t1A32SErhs0lCuKcjj7JOzSNTFY0SipjKQbuXdijqeWVXOs6vK2FLVQILB2Sdnceu5o7ly8lAy0/qEHVGkW1IZSNzbXFkfWQNYXca7FfUkGJw5ajA3zxrF5acOJUsnihM5YSoDiUtbqw4WQDkbdtZhBqePHMQPZk/islOHandQkU6mMpC4sW1XQzAEVM668loATh85kP/ziYlcMTmXIQNUACKxojKQUJXs3sezqyMFsHpHDQDTR2Ty3asmcsXkoeRm9A05oUjvoDKQLld3oJk/LivhmVVlvFMaKYCp+Zl8++MTuGJyLsMzVQAiXU1lIF3G3Vm0diff+9NaKmobmZKXwTeuGM+Vk3N13WCRkKkMpEuU7d3Pdxeu5cX1FUzIHcDvri9gan5mxy8UkS6hMpCYam1zHlhSzE8WbaTN4ZtXjueLs0aRpLODisQVlYHEzNqyGr755GreKa3hY6dk88OrT9VwkEicUhlIp9vX1MLPX9zEfa+/x8C0ZH75uWl8YkquzhIqEsdUBtKpFm+s5DtPr6F0z34+d0Y+d18+gYy05LBjiUgHVAbSKSrrDvD9P6/jmVXljMnpz+N/dxZnjBoUdiwRiZLKQE5IW5vzWGEJP3puPQea2/jaxafw9+ePJiVJ1w0Q6U5UBnLcNlfW8Y0nV/N28R5mjh7E//3UZE7O7h92LBE5DioDOWYHmlv5zeLN/PbVLfRLSeI/5kxh7ow8bSAW6cZUBnJMlmzZxbeeWs3W6gY+NW043/74BAbrFNIi3Z7KQKKyp6GJf39uPfOLShkxKI0HbzmDc8dmhx1LRDqJykCOqq3NeWJ5KT/6ywZq9zfzpfNP5o4Lx+rC8iI9jMpAjujNzdX88Nn1rCuvZfqITP7905MZP3RA2LFEJAZUBvIRmyvruecv63lxfSXDM/vqCGKRXkBlIO/bVd/IL17axMNLt5OWnMhdl4/n5lkjSU3WkJBIT6cyEA40tzLvzWJ+9fJm9jW38vkzRvDVi8dqLyGRXuSYy8DMLgLSgOfdvbnzI0lXcXeeWVXOj5/fQOme/Vw4PodvXjmeMTnpYUcTkS52TGVgZj8FmoA24EvAlVG8JhP4PXAq4MAXgY3AY8BIoBi4xt33HEsWOTFF2/bww2fXsWL7XibkDuDhW6cwa0xW2LFEJCRHLQMz+wnwA3evCWaNAK4JHq+O8nv8gshaxBwz60NkreKbwEvufo+Z3Q3cDdx1zOnlmJXs3sc9z2/g2VXl5KSn8B+fmcJnZuSRmKCNwyK9WUdrBk8Bj5nZs8BvgAeAt4BU4N6OvriZDQDOA24CcPcmoMnMZgPnB4vNA15BZRBTNfub+fXizfzvG8UkJhh3XjSW288bTb8UbTYSkQ7KwN3fAC43s+uB54FfuvuZx/D1RwNVwB/M7DSgCLgTGOLu5cH3KDeznONKLx1qbm3jkaXb+fmL77J3fzOfmZ7HP186jqEZqWFHE5E40tEwURJwGVABfAr4upndBnzb3VdF+fWnA//o7kvN7BdEhoSiYma3A7cDjBgxItqXCZGNwy+ur+RHf1nP1qoGzj55MN/6+AQmDcsIO5qIxKGOxgieBlYSGee/zt1vNLNhwPfNzN39tg5eXwqUuvvSYHoBkTKoMLPcYK0gF6g83Ivd/V6C4aiCggKP7p8k68pq+cEz61iydRejs/vx+xsKuGhCjg4aE5Ej6qgMTnL3q4INv28BuHsZcKuZTe3oi7v7TjMrMbNx7r4RuAhYF9xuBO4J7heeyD9CPvDm5mpu+t+36Z+SxPdnT+JzZ4wgOTEh7FgiEuc6KoN7zWwlkV1Cf9r+CXdfGeX3+Efg4aBQtgI3AwnA42Z2C7AdmHtMqeWwirbt4dYHChk5OI1Hb5upg8ZEJGodbUD+L+C/TuQbBKVRcJinLjqRrysftmZHDTf9YRk56Sk8dMuZKgIROSYaP+gBNlXUccP9y0hPSeKhW88kZ4D2FBKRY6My6Oa27Wrgut8vJcGMh2+bSd7AtLAjiUg3pDLoxsr27ufz/7OUptY2Hr71TEZl9Qs7koh0U1EdfmpmKcBniJxL6P3XuPv3YxNLOlJV18gXfr+U2v3NPHLbTMYN1cnlROT4RXsugoVADZEjiBtjF0eisXdfE9fft5TymgM8cMsZTM7TgWQicmKiLYM8d788pkkkKnUHmrnxD2+ztaqB+286ndNHDgo7koj0ANFuM3jTzCbHNIl0aH9TK7fMK2TNjhp+fd10zhmrU06LSOeIds3gHOAmM3uPyDCRAe7uU2KWTD6ksaWVv3uoiLeLd/OLa6dxycQhYUcSkR4k2jK4IqYp5KhaWtu449EV/O3dKv7jM1P45GnDwo4kIj1MR2ctHeDutUBdF+WRQ7S1Of88/x0Wra3ge5+YyDWn54cdSUR6oI7WDB4BriKyF5ETGR46yIlcr0BixN351tNreHplGf9y2ThunjUq7Egi0kN1dG6iq4J7vQt1MXfnh8+u59Fl2/ny+SfzlQvGhB1JRHowHYEcp3724ibue/09bjp7JP9y2biw44hID6cyiEO/e3ULv3xpE9cU5PHdqybqojQiEnMqgzjz4JJifvSXDVw1JZcffXoKCQkqAhGJvajLwMzOMbObg8fZZqbtCJ1sQVEp31m4losn5PCzz04lUUUgIl0kqjIws+8BdwHfCGYlAw/FKlRv9Nzqcv51wTucMyaLX31+ui5VKSJdKtp3nE8BnwQa4P3rIOs0mZ1k8YZK7vzjCqaPGMi9N8wgNTkx7Egi0stEWwZN7u5Eji3AzHTi/E6ytaqev3+oiHFD07n/5tNJ6xPtQeEiIp0n2jJ43Mx+B2Sa2W3Ai8D/xC5W7zHvzWLc4f4bT2dAanLYcUSkl4rqY6i7/8TMLgFqgXHAd939hZgm6wXqG1t4YvkOrpqSq+sWi0ioOiwDM0sEFrn7xYAKoBM9tbyU+sYWrj/rpLCjiEgv1+Ewkbu3AvvMTJfT6kTuzgNLtjElL4Op+ZlhxxGRXi7arZUHgNVm9gLBHkUA7n5HTFL1Am9t3c2mynr+c84UHWEsIqGLtgyeDW7SSR5YUkxmWjKf0LUJRCQORLsBeZ6Z9QFOCWZtdPfm2MXq2cpr9vPXdRXces4oHVMgInEhqjIws/OBeUAxkWsa5JvZje7+t9hF67keXbqdNne+MFMbjkUkPkQ7TPRT4FJ33whgZqcAjwIzYhWsp2pqaeORZSVcOC6H/EFpYccREQGiP+gs+WARALj7u0TOTyTH6C9ryqmub9TupCISV6JdMyg0s/uAB4Pp64hcClOO0YNLtjFycBrnjc0OO4qIyPuiXTP4ErAWuAO4E1gH/H00LzSzYjNbbWYrzawwmDfIzF4ws03B/cDjCd/drCurpXDbHr4w8yRdp0BE4kq0ZZAE/MLdP+3unwJ+CRzLbjAXuPtUdy8Ipu8GXnL3scBLwXSP9+BbxaQmJzB3Rn7YUUREPiTaMngJ6Ntuui+Rk9Udr9lE9k4iuL/6BL5Wt1Czr5mnVuzg6qnDyUjT5hYRiS/RlkGqu9cfnAgeR7srjAN/NbMiM7s9mDfE3cuDr1UO5BzuhWZ2u5kVmllhVVVVlN8uPs0vKuFAc5s2HItIXIq2DBrMbPrBCTObAeyP8rWz3H06cAXwFTM7L9pw7n6vuxe4e0F2dvfd4NrW5jz01jZmnDSQScN0iicRiT/R7k30VWC+mZUF07nAZ6N5YXBVNNy90syeAs4AKsws193LzSwXqDzG3N3Ka5urKd61j69dckrHC4uIhCDa01G8bWbjiVzLwIAN0ZyOIrgiWoK71wWPLwW+D/wJuBG4J7hfeJz5u4UH3iwmq38KV5yaG3YUEZHDimqYyMzmEtlusIbIxt/H2g8bHcUQ4HUzewdYBjzr7s8TKYFLzGwTcEkw3SOV7N7Hyxsr+dwZ+fRJ0kXuRSQ+RTtM9B13n29m5wCXAT8BfgucebQXuftW4LTDzN8FXHSMWbulh5ZuI8GMz585IuwoIiJHFO1H1dbg/uPAb919IdAnNpF6jgPNrTz+dgmXThxCbkbfjl8gIhKSaMtgh5n9DrgGeM7MUo7htb3Wn98pY8++Zu1OKiJxL9o39GuARcDl7r4XGAT8y8Ene8vpJI7Vg29tY2xOf84aPTjsKCIiRxVVGbj7Pnd/0t03BdPl7v7Xdou8FJN03djKkr2sKq3h+rNO0mUtRSTuddZQj97tDvHAkmL69UnkU9OGhx1FRKRDnVUG3klfp0fYVd/IM++U85kZeaSn6jxEIhL/tBE4Bh4rLKGptY3rdVlLEekmNEzUyVrbnIff2s5Zowczdkh62HFERKJy3GVgZv3bTfaKA8ii8fKGSnbs3c8N2p1URLqRE1kzWHfwgbvv7oQsPcIDS4rJzUjlkolDwo4iIhK1o56Owsy+fqSngP5HeK7X2lpVz2ubqvmnS04hKVGbY0Sk++joHevfgYFA+iG3/lG8ttd58K1tJCca156h8xCJSPfS0YnqlgNPu3vRoU+Y2a2xidQ9NTS2sKColCtOzSU7PSXsOCIix6SjMrgZ2HWE5wqOML9XenrlDuoOtHDj2dpwLCLdT0dDPd9292ozu/PQJ9y9IkaZuh1358El25iYO4DpI3SaJhHpfjoqgxlmdhLwRTMbaGaD2t+6ImB38HbxHjbsrOMGnYdIRLqpjoaJ/ht4HhgNFPHhg8s8mN/rPbCkmAGpScyeqvMQiUj3dNQ1A3f/pbtPAO5399HuPqrdTUUAVNYe4Pk1O5lbkE/fPolhxxEROS7RnsL6S7EO0l09smw7LW2u8xCJSLemYwVOQHNrG48s3c7HTslmZFa/sOOIiBw3lcEJ+OvaCirrGnUeIhHp9lQGJ2DekmLyBvbl/HE5YUcRETkhKoPjtGFnLcve2831M08iMUG7k4pI96YyOE4PLtlGSlIC1xTkhx1FROSEqQyOQ+2BZp5asYNPnDaMgf36hB1HROSEqQyOwxNFpexratWGYxHpMVQGx8jdefCtbUzNz2RKXmbYcUREOoXK4Bi9sXkXW6satFYgIj2KyuAYPbpsOwPTkrlycm7YUUREOk2XlIGZJZrZCjN7JpgeZWZLzWyTmT1mZt1iK+zefU28sK6C2VOHk5qs8xCJSM/RVWsGdwLr203/GPiZu48F9gC3dFGOE/Knd8poam1jbkFe2FFERDpVzMvAzPKAjwO/D6YNuBBYECwyD7g61jk6w/zCUibmDmDSsIywo4iIdKquWDP4OfCvQFswPRjY6+4twXQpEPcXAtiws5bVO2qYM0NrBSLS88S0DMzsKqDS3Yvazz7Mon6E199uZoVmVlhVVRWTjNGaX1hKcqJx9bS47y0RkWMW6zWDWcAnzawY+COR4aGfA5lmdvAqa3lA2eFe7O73unuBuxdkZ2fHOOqRNbe28fSKHVw0fgiDdMSxiPRAMS0Dd/+Gu+e5+0jgWuBld78OWAzMCRa7EVgYyxwnavGGSnY1NGnDsYj0WGEdZ3AX8HUz20xkG8J9IeWIyvyiUrL6p/CxU8JbOxERiaWkjhfpHO7+CvBK8HgrcEZXfe8TUV3fyOINlXzxnFEkJeoYPRHpmfTu1oGnV+ygpc2Zq72IRKQHUxkchbuzoKiU0/IzGTskPew4IiIxozI4ijU7atmws05rBSLS46kMjmJ+UQl9khL4xJRhYUcREYkplcERNLa0snBlGZdNGkpGWnLYcUREYkplcAQvrqukZn+zhohEpFdQGRzB/KIScjNSmTUmK+woIiIxpzI4jJ01B/jbu1V8evpwEhMOdyolEZGeRWVwGE+uKKXNYc6M/LCjiIh0CZXBIQ4eW3D6yIGMyuoXdhwRkS6hMjjE8u172VrVwFytFYhIL6IyOMSCohL6Jidy5RRd8F5Eeg+VQTv7m1r58zvlXDF5KP1TuuwcfiIioVMZtLNo7U7qG1s0RCQivY7KoJ35RSXkD+rLmaMGhR1FRKRLqQwCpXv28eaWXcyZnk+Cji0QkV5GZRB4omgH7vDp6brgvYj0PioDoK3NWbC8hLNPHkz+oLSw44iIdDmVAbCseDclu/frgvci0mupDID5haX0T0ni8kk6tkBEeqdeXwb1jS08t7qcq6bk0rdPYthxRERC0evL4LlV5exvbtUQkYj0ar2+DBYUlTI6ux/TRwwMO4qISGh6dRkUVzewrHg3c2bkYaZjC0Sk9+rVZbCgqJQEg09P0xCRiPRuvbYMWtucJ5aXcu7YbIZmpIYdR0QkVL22DN7cUk15zQFtOBYRoReXwfzCUjL6JnPxhCFhRxERCV2vLIOa/c0sWruT2VOHkZqsYwtERHplGfz5nTIaW9qYM0NDRCIiEOMyMLNUM1tmZu+Y2Voz+7dg/igzW2pmm8zsMTPrE8sch1pQVMq4IelMHp7Rld9WRCRuxXrNoBG40N1PA6YCl5vZTODHwM/cfSywB7glxjnet7myjpUle5lboGMLREQOimkZeER9MJkc3By4EFgQzJ8HXB3LHO3NLywlKcG4epquWyAiclDMtxmYWaKZrQQqgReALcBed28JFikFDvvObGa3m1mhmRVWVVWdcJaW1jaeXLGDC8bnkNU/5YS/nohITxHzMnD3VnefCuQBZwATDrfYEV57r7sXuHtBdnb2CWd59d0qquoateFYROQQXbY3kbvvBV4BZgKZZpYUPJUHlHVFhgVFpQzu14cLx+d0xbcTEek2Yr03UbaZZQaP+wIXA+uBxcCcYLEbgYWxzAGwu6GJF9dXcPW04SQn9so9akVEjiip40VOSC4wz8wSiRTP4+7+jJmtA/5oZj8EVgD3xTgHC1fuoLnVNUQkInIYMS0Dd18FTDvM/K1Eth90mfmFpZw6fAATcgd05bcVEekWesV4ydqyGtaV1zJ3Rn7YUURE4lKvKIMFRaX0SUxg9tRhYUcREYlLPb4MmlraWLiyjEsmDiEzrUvPeiEi0m30+DJ4eUMFuxuamKPrFoiIHFGPL4MFRaXkpKdw7pissKOIiMStWO9aGip3Z+yQdApGDiJJxxaIiBxRjy4DM+Ouy8eHHUNEJO7p47KIiKgMREREZSAiIqgMREQElYGIiKAyEBERVAYiIoLKQEREAHM/7OWH446ZVQHbws4RyAKqww7RgXjPGO/5QBk7Q7zng/jPeKL5TnL3Di8i323KIJ6YWaG7F4Sd42jiPWO85wNl7Azxng/iP2NX5dMwkYiIqAxERERlcLzuDTtAFOI9Y7znA2XsDPGeD+I/Y5fk0zYDERHRmoGIiKgMOmRm95tZpZmtaTdvkJm9YGabgvuBIebLN7PFZrbezNaa2Z1xmDHVzJaZ2TtBxn8L5o8ys6VBxsfMLNSLVJtZopmtMLNn4jRfsZmtNrOVZlYYzIubn3OQJ9PMFpjZhuB38qx4yWhm44L/u4O3WjP7arzka5fza8HfyRozezT4+4n576LKoGP/C1ysRgFoAAAE7UlEQVR+yLy7gZfcfSzwUjAdlhbgn9x9AjAT+IqZTYyzjI3Ahe5+GjAVuNzMZgI/Bn4WZNwD3BJiRoA7gfXtpuMtH8AF7j613a6G8fRzBvgF8Ly7jwdOI/L/GRcZ3X1j8H83FZgB7AOeipd8AGY2HLgDKHD3U4FE4Fq64nfR3XXr4AaMBNa0m94I5AaPc4GNYWdsl20hcEm8ZgTSgOXAmUQOpEkK5p8FLAoxVx6RN4ILgWcAi6d8QYZiIOuQeXHzcwYGAO8RbIuMx4ztMl0KvBFv+YDhQAkwiMiVKJ8BLuuK30WtGRyfIe5eDhDc54ScBwAzGwlMA5YSZxmDIZiVQCXwArAF2OvuLcEipUT+EMLyc+BfgbZgejDxlQ/Agb+aWZGZ3R7Mi6ef82igCvhDMNz2ezPrF2cZD7oWeDR4HDf53H0H8BNgO1AO1ABFdMHvosqghzCz/sATwFfdvTbsPIdy91aPrJ7nAWcAEw63WNemijCzq4BKdy9qP/swi4a9690sd58OXEFkOPC8kPMcKgmYDvzW3acBDYQ/bPURwXj7J4H5YWc5VLC9YjYwChgG9CPy8z5Up/8uqgyOT4WZ5QIE95VhhjGzZCJF8LC7PxnMjquMB7n7XuAVIts3Ms0sKXgqDygLKdYs4JNmVgz8kchQ0c+Jn3wAuHtZcF9JZKz7DOLr51wKlLr70mB6AZFyiKeMEHlzXe7uFcF0POW7GHjP3avcvRl4EjibLvhdVBkcnz8BNwaPbyQyTh8KMzPgPmC9u/+/dk/FU8ZsM8sMHvcl8gu/HlgMzAkWCy2ju3/D3fPcfSSR4YOX3f26eMkHYGb9zCz94GMiY95riKOfs7vvBErMbFww6yJgHXGUMfA5PhgigvjKtx2YaWZpwd/2wf/D2P8uhr0hJ95vRH5pyoFmIp98biEynvwSsCm4HxRivnOIrDKuAlYGtyvjLOMUYEWQcQ3w3WD+aGAZsJnIKntKHPy8zweeibd8QZZ3gtta4FvB/Lj5OQd5pgKFwc/6aWBgPGUksgPDLiCj3by4yRfk+TdgQ/C38iCQ0hW/izoCWURENEwkIiIqAxERQWUgIiKoDEREBJWBiIigMhDpEmZ2/sGzoYrEI5WBiIioDETaM7MvBNdeWGlmvwtOsFdvZj81s+Vm9pKZZQfLTjWzt8xslZk9dfA8+GY2xsxeDK7fsNzMTg6+fP925/p/ODjCVCQuqAxEAmY2AfgskRPCTQVageuInCxsuUdOEvcq8L3gJQ8Ad7n7FGB1u/kPA7/2yPUbziZyBDtEzij7VWAikSNKZ8X8HyUSpaSOFxHpNS4ictGTt4MP7X2JnLSsDXgsWOYh4EkzywAy3f3VYP48YH5w/qDh7v4UgLsfAAi+3jJ3Lw2mVxK5Tsbrsf9niXRMZSDyAQPmufs3PjTT7DuHLHe0c7gcbeinsd3jVvT3J3FEw0QiH3gJmGNmOfD+9YVPIvJ3cvCMkZ8HXnf3GmCPmZ0bzL8eeNUj15IoNbOrg6+RYmZpXfqvEDkO+mQiEnD3dWb2bSJXE0sgcqbarxC5SMskMysicuWpzwYvuRH47+DNfitwczD/euB3Zvb94GvM7cJ/hshx0VlLRTpgZvXu3j/sHCKxpGEiERHRmoGIiGjNQEREUBmIiAgqAxERQWUgIiKoDEREBJWBiIgA/x++pgWX9h5cjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot f1_score of training result\n",
    "\n",
    "ydata = score_per_time\n",
    "xdata = np.zeros(len(ydata))\n",
    "for i in range(0,num_train_f1score_details):\n",
    "    xdata[i] = (i+1)*(epochs/num_train_f1score_details)\n",
    "plt.plot(xdata,ydata*100)\n",
    "plt.ylabel('f1_score in %')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CcoAhyiMp043"
   },
   "source": [
    "## Get accuracy for test and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-kUPRGNQa9mU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3450/3453 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# Predict labels for test dataset   \n",
    "predLabels, correctLabels = tag_dataset(test_batch)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZAJWRrsa9mY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-Data: Prec: 64.835%, Rec: 62.677%, F1: 63.738%\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy of test dataset\n",
    "\n",
    "precision_test, recall_test, f1_test= compute_f1(predLabels, correctLabels, idx2Label)\n",
    "print(\"Test-Data: Prec: %.3f%%, Rec: %.3f%%, F1: %.3f%%\" % (precision_test*100, recall_test*100, f1_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01MBj1w_a9mb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3249/3250 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "#   Performance on validation dataset        \n",
    "predLabels, correctLabels = tag_dataset(dev_batch)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BwzlQA3Xa9mf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation-Data: Prec: 71.792%, Rec: 68.832%, F1: 70.281%\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy of validation dataset\n",
    "\n",
    "precision_dev, recall_dev, f1_dev = compute_f1(predLabels, correctLabels, idx2Label)\n",
    "print(\"Validation-Data: Prec: %.3f%%, Rec: %.3f%%, F1: %.3f%%\" % (precision_dev*100, recall_dev*100, f1_dev*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "simplemodel.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
