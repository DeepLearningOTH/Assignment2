{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5FX2nLGXbDoC"
   },
   "source": [
    "This programm will learn and execute sequence tagging based on LSTM with a following CNN-maxpooling-layer for feature selection.\n",
    "\n",
    "This programm depends on Tensorflow, Keras and Scikit-Learn version 0.20\n",
    "\n",
    "The link to the code is: https://github.com/kamalkraj/Named-Entity-Recognition-with-Bidirectional-LSTM-CNNs\n",
    "\n",
    "\n",
    "But the code was outdated due to scikit-learn >0.16.\n",
    "I updated those problems so it works again.\n",
    "Also the code was split in 3 python files for preprocessing, model and validation which I recombined in this file.\n",
    "\n",
    "Additional a more simple model was added which contains a lstm only. the selection is defined by the cell which will you run. there are more details in the corresponding section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crQp_Mbaa9kW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.layers import TimeDistributed,Conv1D,Dense,Embedding,Input,Dropout,LSTM,Bidirectional,MaxPooling1D,Flatten,concatenate\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import Progbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f-UJAabszSA7"
   },
   "outputs": [],
   "source": [
    "# define pathes to download needed data\n",
    "  # datasets\n",
    "path_train = 'https://raw.githubusercontent.com/Franck-Dernoncourt/NeuroNER/master/data/conll2003/en/train.txt'\n",
    "path_test = 'https://raw.githubusercontent.com/Franck-Dernoncourt/NeuroNER/master/data/conll2003/en/test.txt'\n",
    "path_valid = 'https://raw.githubusercontent.com/Franck-Dernoncourt/NeuroNER/master/data/conll2003/en/valid.txt'\n",
    "\n",
    "  # path to matrix which already contains a mapping from words to vectors. Can be extended locally\n",
    "path_glove = 'http://nlp.stanford.edu/data/glove.6B.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3NpqR8l9a9kc"
   },
   "source": [
    "### Define Methods to preprocess Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jtb1Hslqa9kd"
   },
   "outputs": [],
   "source": [
    "# define how the file with the input-content looks like, build sentences from the file, \n",
    "# per line there will be one sentence. Each word is tagged. The sentences\n",
    "# with later be the train-examples while the tagging will be the learned target\n",
    "\n",
    "def readfile(filename):\n",
    "    '''\n",
    "    read file\n",
    "    return format :\n",
    "    [ ['EU', 'B-ORG'], ['rejects', 'O'], ['German', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['British', 'B-MISC'], ['lamb', 'O'], ['.', 'O'] ]\n",
    "    '''\n",
    "    f = open(filename)\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for line in f:\n",
    "        if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
    "            if len(sentence) > 0:\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "            continue\n",
    "        splits = line.split(' ')\n",
    "        sentence.append([splits[0],splits[-1]])\n",
    "\n",
    "    if len(sentence) >0:\n",
    "        sentences.append(sentence)\n",
    "        sentence = []\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zWqeQTC5a9kh"
   },
   "outputs": [],
   "source": [
    "# define the casing, so we have a word classification. Important words like\n",
    "# names, organization names, countries, towns \n",
    "# are normally written in initialUpperCase or allUpperCase\n",
    "# while for example verbs and adjectives in lowercase.\n",
    "\n",
    "# So the casing helps to get a better result because we have an important\n",
    "# additional classification\n",
    "\n",
    "def getCasing(word, caseLookup):   \n",
    "    casing = 'other'\n",
    "    \n",
    "    numDigits = 0\n",
    "    for char in word:\n",
    "        if char.isdigit():\n",
    "            numDigits += 1\n",
    "            \n",
    "    digitFraction = numDigits / float(len(word))\n",
    "    \n",
    "    if word.isdigit(): #Is a digit\n",
    "        casing = 'numeric'\n",
    "    elif digitFraction > 0.5:\n",
    "        casing = 'mainly_numeric'\n",
    "    elif word.islower(): #All lower case\n",
    "        casing = 'allLower'\n",
    "    elif word.isupper(): #All upper case\n",
    "        casing = 'allUpper'\n",
    "    elif word[0].isupper(): #is a title, initial char upper, then all lower\n",
    "        casing = 'initialUpper'\n",
    "    elif numDigits > 0:\n",
    "        casing = 'contains_digit'\n",
    "    \n",
    "   \n",
    "    return caseLookup[casing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WQBm-a3va9kk"
   },
   "outputs": [],
   "source": [
    "# split the data into small batches, so the processing will be faster\n",
    "# there will be many text examples which could use a lot of memory so \n",
    "# splitting the data in batches is very useful\n",
    "\n",
    "def createBatches(data):\n",
    "    l = []\n",
    "    for i in data:\n",
    "        l.append(len(i[0]))\n",
    "    l = set(l)\n",
    "    batches = []\n",
    "    batch_len = []\n",
    "    z = 0\n",
    "    for i in l:\n",
    "        for batch in data:\n",
    "            if len(batch[0]) == i:\n",
    "                batches.append(batch)\n",
    "                z += 1\n",
    "        batch_len.append(z)\n",
    "    return batches,batch_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSWt_zkua9ko"
   },
   "outputs": [],
   "source": [
    "# here we preprocess the data, so we have the words (as unique numbers which can be processed),\n",
    "# the casing, and the word as a sequence of cased chars (which can be represented \n",
    "# as numbers and so they can be processed, too).\n",
    "# Also all labels will be represented in an array so the words can be classified correctly. \n",
    "\n",
    "# the output will be a matrix which contains the whole dataset of \n",
    "# processable numbers and chars and the label classification.\n",
    "\n",
    "def createMatrices(sentences, word2Idx, label2Idx, case2Idx,char2Idx):\n",
    "    unknownIdx = word2Idx['UNKNOWN_TOKEN']\n",
    "    paddingIdx = word2Idx['PADDING_TOKEN']    \n",
    "        \n",
    "    dataset = []\n",
    "    \n",
    "    wordCount = 0\n",
    "    unknownWordCount = 0\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        wordIndices = []    \n",
    "        caseIndices = []\n",
    "        charIndices = []\n",
    "        labelIndices = []\n",
    "        \n",
    "        for word,char,label in sentence:  \n",
    "            wordCount += 1\n",
    "            if word in word2Idx:\n",
    "                wordIdx = word2Idx[word]\n",
    "            elif word.lower() in word2Idx:\n",
    "                wordIdx = word2Idx[word.lower()]                 \n",
    "            else:\n",
    "                wordIdx = unknownIdx\n",
    "                unknownWordCount += 1\n",
    "            charIdx = []\n",
    "            for x in char:\n",
    "                charIdx.append(char2Idx[x])\n",
    "            #Get the label and map to int            \n",
    "            wordIndices.append(wordIdx)\n",
    "            caseIndices.append(getCasing(word, case2Idx))\n",
    "            charIndices.append(charIdx)\n",
    "            labelIndices.append(label2Idx[label])\n",
    "           \n",
    "        dataset.append([wordIndices, caseIndices, charIndices, labelIndices]) \n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7pbaK_yra9ks"
   },
   "outputs": [],
   "source": [
    "# the iterator will be defined now, so we can later iterate over the dataset\n",
    "# to learn every single data\n",
    "\n",
    "def iterate_minibatches(dataset,batch_len): \n",
    "    start = 0\n",
    "    for i in batch_len:\n",
    "        tokens = []\n",
    "        caseing = []\n",
    "        char = []\n",
    "        labels = []\n",
    "        data = dataset[start:i]\n",
    "        start = i\n",
    "        for dt in data:\n",
    "            t,c,ch,l = dt\n",
    "            l = np.expand_dims(l,-1)\n",
    "            tokens.append(t)\n",
    "            caseing.append(c)\n",
    "            char.append(ch)\n",
    "            labels.append(l)\n",
    "        yield np.asarray(labels),np.asarray(tokens),np.asarray(caseing),np.asarray(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLC_3Eg_a9kv"
   },
   "outputs": [],
   "source": [
    "def addCharInformation(Sentences):\n",
    "    for i,sentence in enumerate(Sentences):\n",
    "        for j,data in enumerate(sentence):\n",
    "            chars = [c for c in data[0]]\n",
    "            Sentences[i][j] = [data[0],chars,data[1]]\n",
    "    return Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70TwonEza9kz"
   },
   "outputs": [],
   "source": [
    "# define a padding so each sentence will have the same length for processing the data\n",
    "\n",
    "def padding(Sentences):\n",
    "    maxlen = 52\n",
    "    for sentence in Sentences:\n",
    "        char = sentence[2]\n",
    "        for x in char:\n",
    "            maxlen = max(maxlen,len(x))\n",
    "    for i,sentence in enumerate(Sentences):\n",
    "        Sentences[i][2] = pad_sequences(Sentences[i][2],52,padding='post')\n",
    "    return Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-yHV8tdta9k4"
   },
   "source": [
    "### Prepare Model and define common variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aR1Rdy9ra9k5"
   },
   "outputs": [],
   "source": [
    "# Define common variables\n",
    "\n",
    "epochs = 80\n",
    "num_train_f1score_details = 16 # this is how often the f1score will be calculated and displayed while training (example: 50 epochs and this value = 10 will result in displaying the scores in epoch 5, 10, 15, 20, 25, 30, 35, 40, 45, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fLUfZ-YKa9k-"
   },
   "outputs": [],
   "source": [
    "# define how to learn the tagging of the dataset\n",
    "\n",
    "def tag_dataset(dataset):\n",
    "    correctLabels = []\n",
    "    predLabels = []\n",
    "    b = Progbar(len(dataset))\n",
    "    for i,data in enumerate(dataset):    \n",
    "        tokens, casing,char, labels = data\n",
    "        tokens = np.asarray([tokens])     \n",
    "        casing = np.asarray([casing])\n",
    "        char = np.asarray([char])\n",
    "        pred = model.predict([tokens, casing,char], verbose=False)[0]   \n",
    "        pred = pred.argmax(axis=-1) #Predict the classes of labels           \n",
    "        correctLabels.append(labels)\n",
    "        predLabels.append(pred)\n",
    "        b.update(i)\n",
    "    return predLabels, correctLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W3BB7pzZa9lA"
   },
   "outputs": [],
   "source": [
    "# define how to get the train, test and validation data\n",
    "\n",
    "path_to_train_file = tf.keras.utils.get_file('train.txt', path_train)\n",
    "path_to_test_file = tf.keras.utils.get_file('test.txt', path_test)\n",
    "path_to_validation_file = tf.keras.utils.get_file('valid.txt', path_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CdkyOuZaa9lE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Simon\\\\.keras\\\\datasets\\\\train.txt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check where the file is available\n",
    "\n",
    "path_to_train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNs_O6_aa9lI"
   },
   "outputs": [],
   "source": [
    "# read the files to get the raw content\n",
    "\n",
    "trainSentences = readfile(path_to_train_file)\n",
    "devSentences = readfile(path_to_validation_file)\n",
    "testSentences = readfile(path_to_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZG_-ufba9lM"
   },
   "outputs": [],
   "source": [
    "trainSentences = addCharInformation(trainSentences)\n",
    "devSentences = addCharInformation(devSentences)\n",
    "testSentences = addCharInformation(testSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYr5N6cga9lO"
   },
   "outputs": [],
   "source": [
    "# prepare the labelSet and the sentences\n",
    "\n",
    "labelSet = set()\n",
    "words = {}\n",
    "\n",
    "for dataset in [trainSentences, devSentences, testSentences]:\n",
    "    for sentence in dataset:\n",
    "        for token,char,label in sentence:\n",
    "            labelSet.add(label)\n",
    "            words[token.lower()] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u1sB22hoa9lS"
   },
   "outputs": [],
   "source": [
    "# :: Create a mapping for the labels ::\n",
    "label2Idx = {}\n",
    "for label in labelSet:\n",
    "    label2Idx[label] = len(label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYdKTiN5a9lW"
   },
   "outputs": [],
   "source": [
    "# :: Hard coded case lookup ::\n",
    "case2Idx = {'numeric': 0, 'allLower':1, 'allUpper':2, 'initialUpper':3, 'other':4, 'mainly_numeric':5, 'contains_digit': 6, 'PADDING_TOKEN':7}\n",
    "caseEmbeddings = np.identity(len(case2Idx), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgLOb7DOa9la"
   },
   "outputs": [],
   "source": [
    "# :: Read in word embeddings ::\n",
    "word2Idx = {}\n",
    "wordEmbeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oe566ZP_a9li",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepared matrix which contains a mapping from the most common train_words to vectors to be faster here. Other words will be added locally.\n",
    "path_to_emb_file_zip = tf.keras.utils.get_file('glove.6B', path_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9LUBVhMa9lm"
   },
   "outputs": [],
   "source": [
    "# read the file which contains the prepared matrix, the file with 100d is chosen, \n",
    "# there are also files with 50d and 300d available in the zip \n",
    "# the only difference is the performance of the learner and this programm to read all vectors\n",
    "zip = zipfile.ZipFile(path_to_emb_file_zip)\n",
    "fEmbeddings = zip.open('glove.6B.100d.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5kUXha4Ea9lp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zipfile.ZipExtFile name='glove.6B.100d.txt' mode='r' compress_type=deflate>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the file-reading is ok\n",
    "fEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xt0jTsjSa9lw"
   },
   "outputs": [],
   "source": [
    "# adapt the vector with the prepared matrix (mapping word->vector) to\n",
    "# our examples to have a more words to choose and classify which can \n",
    "# influence our model in both ways (making it better because we know more words\n",
    "# which can help with new sentences for example in the tests,\n",
    "# or making it worse because we have more words as we need)\n",
    "\n",
    "for line in fEmbeddings:\n",
    "    split = line.strip().split(b' ')\n",
    "    word = split[0]\n",
    "    \n",
    "    if len(word2Idx) == 0: #Add padding+unknown\n",
    "        word2Idx[\"PADDING_TOKEN\"] = len(word2Idx)\n",
    "        vector = np.zeros(len(split)-1) #Zero vector vor 'PADDING' word\n",
    "        wordEmbeddings.append(vector)\n",
    "        \n",
    "        word2Idx[\"UNKNOWN_TOKEN\"] = len(word2Idx)\n",
    "        vector = np.random.uniform(-0.25, 0.25, len(split)-1)\n",
    "        wordEmbeddings.append(vector)\n",
    "\n",
    "    if split[0].lower() in words:\n",
    "        vector = np.array([float(num) for num in split[1:]])\n",
    "        wordEmbeddings.append(vector)\n",
    "        word2Idx[split[0]] = len(word2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WP34N08Ia9lz"
   },
   "outputs": [],
   "source": [
    "#classify known vs. unknown token\n",
    "\n",
    "wordEmbeddings = np.array(wordEmbeddings)\n",
    "char2Idx = {\"PADDING_TOKEN\":0, \"UNKNOWN_TOKEN\":1}\n",
    "for c in \" 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ.,-_()[]{}!?:;#'\\\"/\\\\%$`&=*+@^~|\":\n",
    "    char2Idx[c] = len(char2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IPM2tUQra9l1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PADDING_TOKEN': 0, 'UNKNOWN_TOKEN': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2Idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PjZ95eEBn-Sg"
   },
   "source": [
    "Real data preprocessing - from the dataset(sentences and labels)  to the processable matrices with paddings, and preparing the batches - starts now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bf2awUcRa9l5"
   },
   "outputs": [],
   "source": [
    "# create the padding around our sentences in the datasets now\n",
    "\n",
    "train_set = padding(createMatrices(trainSentences,word2Idx,label2Idx,case2Idx,char2Idx))\n",
    "dev_set = padding(createMatrices(devSentences,word2Idx,label2Idx,case2Idx,char2Idx))\n",
    "test_set = padding(createMatrices(testSentences,word2Idx,label2Idx,case2Idx,char2Idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPrKsmQ7a9l9"
   },
   "outputs": [],
   "source": [
    "# create mapping position to label\n",
    "\n",
    "idx2Label = {v: k for k, v in label2Idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vb6jmINya9mA"
   },
   "outputs": [],
   "source": [
    "# create the batches\n",
    "\n",
    "train_batch,train_batch_len = createBatches(train_set)\n",
    "dev_batch,dev_batch_len = createBatches(dev_set)\n",
    "test_batch,test_batch_len = createBatches(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLY RUN ONE OF THE FOLLOWING TWO MODEL-ARCHITECTURES\n",
    "## The first one is more complex with a bidirectional lstm and a cnn layer with maxpooling \n",
    "## The second one is a simple lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0k4Z5dqva9mF"
   },
   "outputs": [],
   "source": [
    "words_input = Input(shape=(None,),dtype='int32',name='words_input')\n",
    "words = Embedding(input_dim=wordEmbeddings.shape[0], output_dim=wordEmbeddings.shape[1],  weights=[wordEmbeddings], trainable=False)(words_input)\n",
    "casing_input = Input(shape=(None,), dtype='int32', name='casing_input')\n",
    "casing = Embedding(output_dim=caseEmbeddings.shape[1], input_dim=caseEmbeddings.shape[0], weights=[caseEmbeddings], trainable=False)(casing_input)\n",
    "character_input=Input(shape=(None,52,),name='char_input')\n",
    "embed_char_out=TimeDistributed(Embedding(len(char2Idx),30,embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(character_input)\n",
    "dropout= Dropout(0.5)(embed_char_out)\n",
    "conv1d_out= TimeDistributed(Conv1D(kernel_size=3, filters=30, padding='same',activation='tanh', strides=1))(dropout)\n",
    "maxpool_out=TimeDistributed(MaxPooling1D(52))(conv1d_out)\n",
    "char = TimeDistributed(Flatten())(maxpool_out)\n",
    "char = Dropout(0.5)(char)\n",
    "output = concatenate([words, casing,char])\n",
    "output = Bidirectional(LSTM(200, return_sequences=True, dropout=0.50, recurrent_dropout=0.25))(output)\n",
    "output = TimeDistributed(Dense(len(label2Idx), activation='softmax'))(output)\n",
    "model = Model(inputs=[words_input, casing_input,character_input], outputs=[output])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 30) 2850        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 1560)   0           char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 100)    200         words_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 1560)   0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, 1668)   0           embedding_4[0][0]                \n",
      "                                                                 embedding_5[0][0]                \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 200)    1495200     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 9)      1809        lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,500,123\n",
      "Trainable params: 1,499,859\n",
      "Non-trainable params: 264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "words_input = Input(shape=(None,),dtype='int32',name='words_input')\n",
    "words = Embedding(input_dim=wordEmbeddings.shape[0], output_dim=wordEmbeddings.shape[1],  weights=[wordEmbeddings], trainable=False)(words_input)\n",
    "casing_input = Input(shape=(None,), dtype='int32', name='casing_input')\n",
    "casing = Embedding(output_dim=caseEmbeddings.shape[1], input_dim=caseEmbeddings.shape[0], weights=[caseEmbeddings], trainable=False)(casing_input)\n",
    "character_input=Input(shape=(None,52,),name='char_input')\n",
    "embed_char_out=TimeDistributed(Embedding(len(char2Idx),30,embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(character_input)\n",
    "char = TimeDistributed(Flatten())(embed_char_out)\n",
    "char = Dropout(0.5)(char)\n",
    "output = concatenate([words, casing,char])\n",
    "output = LSTM(200, return_sequences=True, dropout=0.50, recurrent_dropout=0.25)(output)\n",
    "output = TimeDistributed(Dense(len(label2Idx), activation='softmax'))(output)\n",
    "model = Model(inputs=[words_input, casing_input,character_input], outputs=[output])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cXYHZWDypCjS"
   },
   "source": [
    "## Define Methods for getting any validation score, here the accuracy will be defined by the f1score via the precision and the recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KmY48HRda9mR"
   },
   "outputs": [],
   "source": [
    "def compute_precision(guessed_sentences, correct_sentences):\n",
    "    assert(len(guessed_sentences) == len(correct_sentences))\n",
    "    correctCount = 0\n",
    "    count = 0\n",
    "    \n",
    "    \n",
    "    for sentenceIdx in range(len(guessed_sentences)):\n",
    "        guessed = guessed_sentences[sentenceIdx]\n",
    "        correct = correct_sentences[sentenceIdx]\n",
    "        assert(len(guessed) == len(correct))\n",
    "        idx = 0\n",
    "        while idx < len(guessed):\n",
    "            if guessed[idx][0] == 'B': #A new chunk starts\n",
    "                count += 1\n",
    "                \n",
    "                if guessed[idx] == correct[idx]:\n",
    "                    idx += 1\n",
    "                    correctlyFound = True\n",
    "                    \n",
    "                    while idx < len(guessed) and guessed[idx][0] == 'I': #Scan until it no longer starts with I\n",
    "                        if guessed[idx] != correct[idx]:\n",
    "                            correctlyFound = False\n",
    "                        \n",
    "                        idx += 1\n",
    "                    \n",
    "                    if idx < len(guessed):\n",
    "                        if correct[idx][0] == 'I': #The chunk in correct was longer\n",
    "                            correctlyFound = False\n",
    "                        \n",
    "                    \n",
    "                    if correctlyFound:\n",
    "                        correctCount += 1\n",
    "                else:\n",
    "                    idx += 1\n",
    "            else:  \n",
    "                idx += 1\n",
    "    \n",
    "    precision = 0\n",
    "    if count > 0:    \n",
    "        precision = float(correctCount) / count\n",
    "        \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZYJk7VLa9mO"
   },
   "outputs": [],
   "source": [
    "#Method to compute the accuracy. Call predict_labels to get the labels for the dataset\n",
    "def compute_f1(predictions, correct, idx2Label): \n",
    "    label_pred = []    \n",
    "    for sentence in predictions:\n",
    "        label_pred.append([idx2Label[element] for element in sentence])\n",
    "        \n",
    "    label_correct = []    \n",
    "    for sentence in correct:\n",
    "        label_correct.append([idx2Label[element] for element in sentence])\n",
    "            \n",
    "    \n",
    "    #print label_pred\n",
    "    #print label_correct\n",
    "    \n",
    "    prec = compute_precision(label_pred, label_correct)\n",
    "    rec = compute_precision(label_correct, label_pred)\n",
    "    \n",
    "    f1 = 0\n",
    "    if (rec+prec) > 0:\n",
    "        f1 = 2.0 * prec * rec / (prec + rec);\n",
    "        \n",
    "    return prec, rec, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B7_l1fcpo_SW"
   },
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define array to save f1_scores during training to get an impression of the training quality\n",
    "\n",
    "score_per_time = np.zeros(num_train_f1score_details) # in the epochs defined by num_train_f1score_details (see calculation above) the f1_score can be saved here\n",
    "score_per_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuryIaGna9mJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 1/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 2/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 3/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 4/80\n",
      "14040/14041 [============================>.] - ETA: 0sPrec: 25.691%, Rec: 25.750%, F1: 25.720%\n",
      " \n",
      "Epoch 5/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 6/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 7/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 8/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 9/80\n",
      "14039/14041 [============================>.] - ETA: 0sPrec: 42.729%, Rec: 38.627%, F1: 40.575%\n",
      " \n",
      "Epoch 10/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 11/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 12/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 13/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 14/80\n",
      "14040/14041 [============================>.] - ETA: 0sPrec: 55.525%, Rec: 51.019%, F1: 53.177%\n",
      " \n",
      "Epoch 15/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 16/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 17/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 18/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 19/80\n",
      "14040/14041 [============================>.] - ETA: 0sPrec: 61.490%, Rec: 58.049%, F1: 59.720%\n",
      " \n",
      "Epoch 20/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 21/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 22/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 23/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 24/80\n",
      "14039/14041 [============================>.] - ETA: 0sPrec: 64.704%, Rec: 59.905%, F1: 62.212%\n",
      " \n",
      "Epoch 25/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 26/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 27/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 28/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 29/80\n",
      "14039/14041 [============================>.] - ETA: 0sPrec: 66.895%, Rec: 63.875%, F1: 65.350%\n",
      " \n",
      "Epoch 30/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 31/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 32/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 33/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 34/80\n",
      "14039/14041 [============================>.] - ETA: 0sPrec: 67.549%, Rec: 65.020%, F1: 66.260%\n",
      " \n",
      "Epoch 35/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 36/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 37/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 38/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 39/80\n",
      "14040/14041 [============================>.] - ETA: 0sPrec: 70.064%, Rec: 67.109%, F1: 68.555%\n",
      " \n",
      "Epoch 40/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 41/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 42/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 43/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 44/80\n",
      "14040/14041 [============================>.] - ETA: 0sPrec: 71.955%, Rec: 68.590%, F1: 70.232%\n",
      " \n",
      "Epoch 45/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 46/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 47/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 48/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 49/80\n",
      "14040/14041 [============================>.] - ETA: 0sPrec: 73.944%, Rec: 71.156%, F1: 72.523%\n",
      " \n",
      "Epoch 50/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 51/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 52/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 53/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 54/80\n",
      "14040/14041 [============================>.] - ETA: 0sPrec: 74.114%, Rec: 71.288%, F1: 72.674%\n",
      " \n",
      "Epoch 55/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 56/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 57/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 58/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 59/80\n",
      "14039/14041 [============================>.] - ETA: 0sPrec: 74.736%, Rec: 73.680%, F1: 74.204%\n",
      " \n",
      "Epoch 60/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 61/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 62/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 63/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 64/80\n",
      "14040/14041 [============================>.] - ETA: 0sPrec: 76.841%, Rec: 74.807%, F1: 75.811%\n",
      " \n",
      "Epoch 65/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 66/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 67/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 68/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 69/80\n",
      "14040/14041 [============================>.] - ETA: 0sPrec: 77.267%, Rec: 75.561%, F1: 76.404%\n",
      " \n",
      "Epoch 70/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 71/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 72/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 73/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 74/80\n",
      "14040/14041 [============================>.] - ETA: 0sPrec: 78.200%, Rec: 76.739%, F1: 77.463%\n",
      " \n",
      "Epoch 75/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 76/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 77/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 78/80\n",
      "63/64 [============================>.] - ETA: 0s \n",
      "Epoch 79/80\n",
      "14040/14041 [============================>.] - ETA: 0sPrec: 79.165%, Rec: 77.663%, F1: 78.407%\n",
      " \n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for epoch in range(epochs):    \n",
    "    print(\"Epoch %d/%d\"%(epoch,epochs))\n",
    "    a = Progbar(len(train_batch_len))\n",
    "    for i,batch in enumerate(iterate_minibatches(train_batch,train_batch_len)):\n",
    "        labels, tokens, casing,char = batch       \n",
    "        model.train_on_batch([tokens, casing,char], labels)\n",
    "               \n",
    "        a.update(i)\n",
    "    if epoch % (epochs/num_train_f1score_details) == (epochs/num_train_f1score_details)-1:\n",
    "        predLabels, correctLabels = tag_dataset(train_batch)  \n",
    "        precision_train, recall_train, f1_train= compute_f1(predLabels, correctLabels, idx2Label)\n",
    "        score_per_time[index] = f1_train\n",
    "        index = index + 1\n",
    "        print(\"Prec: %.3f%%, Rec: %.3f%%, F1: %.3f%%\" % (precision_train*100, recall_train*100, f1_train*100))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot f1_score of training result\n",
    "\n",
    "ydata = score_per_time\n",
    "xdata = np.zeros(len(ydata))\n",
    "for i in range(0,num_train_f1score_details):\n",
    "    xdata[i] = (i+1)*(epochs/num_train_f1score_details)\n",
    "plt.plot(xdata,ydata*100)\n",
    "plt.ylabel('f1_score in %')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CcoAhyiMp043"
   },
   "source": [
    "## Get accuracy for test and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-kUPRGNQa9mU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3452/3453 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# Predict labels for test dataset   \n",
    "predLabels, correctLabels = tag_dataset(test_batch)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZAJWRrsa9mY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-Data: Prec: 63.873%, Rec: 62.890%, F1: 63.378%\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy of test dataset\n",
    "\n",
    "precision_test, recall_test, f1_test= compute_f1(predLabels, correctLabels, idx2Label)\n",
    "print(\"Test-Data: Prec: %.3f%%, Rec: %.3f%%, F1: %.3f%%\" % (precision_test*100, recall_test*100, f1_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01MBj1w_a9mb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3249/3250 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "#   Performance on validation dataset        \n",
    "predLabels, correctLabels = tag_dataset(dev_batch)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BwzlQA3Xa9mf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation-Data: Prec: 71.228%, Rec: 69.993%, F1: 70.605%\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy of validation dataset\n",
    "\n",
    "precision_dev, recall_dev, f1_dev = compute_f1(predLabels, correctLabels, idx2Label)\n",
    "print(\"Validation-Data: Prec: %.3f%%, Rec: %.3f%%, F1: %.3f%%\" % (precision_dev*100, recall_dev*100, f1_dev*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "simplemodel.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
